{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21_Quick_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "dwEdLgZpFibi",
        "zvqPQxmgFibo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KiyongAhn/rep01/blob/master/21_Quick_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZc219MFFibh",
        "colab_type": "text"
      },
      "source": [
        "# Keras로 Linear&Logistic Regression 맛보기!\n",
        "\n",
        "### Your name :\n",
        "\n",
        "### Kaggle Link for exercise :\n",
        "* [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer) : \n",
        "\n",
        "#### 실습목표<br>\n",
        "1. keras의 모델링 아이디어를 이해한다.\n",
        "2. 모든 코드를 이해한다.\n",
        "3. (Optional)TensorFlow보다 쉬움을 느낀다!\n",
        "\n",
        "--------------------------\n",
        "Rayleigh Kim @ D:plus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwEdLgZpFibi",
        "colab_type": "text"
      },
      "source": [
        "## Quick Linear Regression!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvObzQ1MFibj",
        "colab_type": "code",
        "outputId": "9b6b6cac-71a7-4ddc-b141-897337515b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import keras\n",
        "import numpy\n",
        "\n",
        "x = numpy.array(range(0,20)) \n",
        "y = x * 2 -1 \n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
            "[-1  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUqZACd2IRcn",
        "colab_type": "code",
        "outputId": "2a27e804-730c-460b-c714-9f0dffe580b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# model에 순차적으로 레이어를 쌓아가겠다는 의도!\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# 인풋을 받아, weight을 곱하고, bias를 더해주는거 까지 한 번에 해주는 거\n",
        "lc = keras.layers.Dense(1,input_shape=(1,))\n",
        "\n",
        "# model에 위에꺼 lc를 집어 넣을거야. (최초의 레이어)\n",
        "model.add(lc)\n",
        "\n",
        "# 컴파일 해주렴\n",
        "model.compile(loss = 'mse', optimizer = 'sgd')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0710 05:43:41.773581 140133420881792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0710 05:43:41.776514 140133420881792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0710 05:43:41.814847 140133420881792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0710 05:43:41.820470 140133420881792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0710 05:43:41.826614 140133420881792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0710 05:43:41.846560 140133420881792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1UM3mOzLTeb",
        "colab_type": "code",
        "outputId": "5e356d65-58c9-4cd5-e3f6-cf28fd0c5396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "# 데이터를 넣어서 학습시키자!\n",
        "model.fit(x[:15], y[:15], epochs=10, verbose=1)\n",
        "\n",
        "# 결과 출력해줘!\n",
        "print(y[15:])\n",
        "print(model.predict(x[15:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 138.0064\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 525us/step - loss: 18.9863\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 492us/step - loss: 2.8757\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 364us/step - loss: 0.6921\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 388us/step - loss: 0.3933\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 419us/step - loss: 0.3496\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 329us/step - loss: 0.3405\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 212us/step - loss: 0.3360\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 344us/step - loss: 0.3323\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 282us/step - loss: 0.3286\n",
            "[29 31 33 35 37]\n",
            "[[28.393318]\n",
            " [30.280506]\n",
            " [32.167694]\n",
            " [34.054882]\n",
            " [35.942074]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvqPQxmgFibo",
        "colab_type": "text"
      },
      "source": [
        "## Now, Your turn!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIFzEwY2PWpX",
        "colab_type": "code",
        "outputId": "6c992f48-fdcd-4b61-8234-5cc5762f3483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import keras\n",
        "import numpy\n",
        "\n",
        "x = numpy.array(range(0,20)) \n",
        "y = x * (-3) + 10 \n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
            "[ 10   7   4   1  -2  -5  -8 -11 -14 -17 -20 -23 -26 -29 -32 -35 -38 -41\n",
            " -44 -47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNul2_K5PhGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# model에 순차적으로 레이어를 쌓아가겠다는 의도!\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# 인풋을 받아, weight을 곱하고, bias를 더해주는거 까지 한 번에 해주는 거\n",
        "lc = keras.layers.Dense(1,input_shape=(1,))\n",
        "\n",
        "# model에 위에꺼 lc를 집어 넣을거야. (최초의 레이어)\n",
        "model.add(lc)\n",
        "\n",
        "# 컴파일 해주렴\n",
        "model.compile(loss = 'mse', optimizer = 'sgd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhr1VsJzQcGI",
        "colab_type": "code",
        "outputId": "751e4e88-6ad9-4da3-b80f-d825e7d7e70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 데이터를 넣어서 학습시키자!\n",
        "model.fit(x[:15], y[:15], epochs=700, verbose=1)\n",
        "\n",
        "# 결과 출력해줘!\n",
        "print(y[15:])\n",
        "print(model.predict(x[15:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/700\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 773.4437\n",
            "Epoch 2/700\n",
            "15/15 [==============================] - 0s 293us/step - loss: 129.8576\n",
            "Epoch 3/700\n",
            "15/15 [==============================] - 0s 272us/step - loss: 42.4857\n",
            "Epoch 4/700\n",
            "15/15 [==============================] - 0s 468us/step - loss: 30.3902\n",
            "Epoch 5/700\n",
            "15/15 [==============================] - 0s 187us/step - loss: 28.4851\n",
            "Epoch 6/700\n",
            "15/15 [==============================] - 0s 459us/step - loss: 27.9619\n",
            "Epoch 7/700\n",
            "15/15 [==============================] - 0s 272us/step - loss: 27.6286\n",
            "Epoch 8/700\n",
            "15/15 [==============================] - 0s 215us/step - loss: 27.3239\n",
            "Epoch 9/700\n",
            "15/15 [==============================] - 0s 236us/step - loss: 27.0259\n",
            "Epoch 10/700\n",
            "15/15 [==============================] - 0s 249us/step - loss: 26.7316\n",
            "Epoch 11/700\n",
            "15/15 [==============================] - 0s 218us/step - loss: 26.4406\n",
            "Epoch 12/700\n",
            "15/15 [==============================] - 0s 194us/step - loss: 26.1527\n",
            "Epoch 13/700\n",
            "15/15 [==============================] - 0s 265us/step - loss: 25.8680\n",
            "Epoch 14/700\n",
            "15/15 [==============================] - 0s 367us/step - loss: 25.5863\n",
            "Epoch 15/700\n",
            "15/15 [==============================] - 0s 424us/step - loss: 25.3077\n",
            "Epoch 16/700\n",
            "15/15 [==============================] - 0s 194us/step - loss: 25.0322\n",
            "Epoch 17/700\n",
            "15/15 [==============================] - 0s 292us/step - loss: 24.7597\n",
            "Epoch 18/700\n",
            "15/15 [==============================] - 0s 243us/step - loss: 24.4901\n",
            "Epoch 19/700\n",
            "15/15 [==============================] - 0s 241us/step - loss: 24.2235\n",
            "Epoch 20/700\n",
            "15/15 [==============================] - 0s 204us/step - loss: 23.9597\n",
            "Epoch 21/700\n",
            "15/15 [==============================] - 0s 184us/step - loss: 23.6989\n",
            "Epoch 22/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 23.4409\n",
            "Epoch 23/700\n",
            "15/15 [==============================] - 0s 289us/step - loss: 23.1857\n",
            "Epoch 24/700\n",
            "15/15 [==============================] - 0s 310us/step - loss: 22.9332\n",
            "Epoch 25/700\n",
            "15/15 [==============================] - 0s 195us/step - loss: 22.6835\n",
            "Epoch 26/700\n",
            "15/15 [==============================] - 0s 286us/step - loss: 22.4366\n",
            "Epoch 27/700\n",
            "15/15 [==============================] - 0s 228us/step - loss: 22.1923\n",
            "Epoch 28/700\n",
            "15/15 [==============================] - 0s 274us/step - loss: 21.9507\n",
            "Epoch 29/700\n",
            "15/15 [==============================] - 0s 278us/step - loss: 21.7117\n",
            "Epoch 30/700\n",
            "15/15 [==============================] - 0s 237us/step - loss: 21.4753\n",
            "Epoch 31/700\n",
            "15/15 [==============================] - 0s 248us/step - loss: 21.2415\n",
            "Epoch 32/700\n",
            "15/15 [==============================] - 0s 359us/step - loss: 21.0102\n",
            "Epoch 33/700\n",
            "15/15 [==============================] - 0s 319us/step - loss: 20.7815\n",
            "Epoch 34/700\n",
            "15/15 [==============================] - 0s 328us/step - loss: 20.5552\n",
            "Epoch 35/700\n",
            "15/15 [==============================] - 0s 331us/step - loss: 20.3314\n",
            "Epoch 36/700\n",
            "15/15 [==============================] - 0s 366us/step - loss: 20.1101\n",
            "Epoch 37/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 19.8911\n",
            "Epoch 38/700\n",
            "15/15 [==============================] - 0s 207us/step - loss: 19.6746\n",
            "Epoch 39/700\n",
            "15/15 [==============================] - 0s 310us/step - loss: 19.4604\n",
            "Epoch 40/700\n",
            "15/15 [==============================] - 0s 360us/step - loss: 19.2485\n",
            "Epoch 41/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 19.0389\n",
            "Epoch 42/700\n",
            "15/15 [==============================] - 0s 211us/step - loss: 18.8317\n",
            "Epoch 43/700\n",
            "15/15 [==============================] - 0s 216us/step - loss: 18.6266\n",
            "Epoch 44/700\n",
            "15/15 [==============================] - 0s 199us/step - loss: 18.4238\n",
            "Epoch 45/700\n",
            "15/15 [==============================] - 0s 206us/step - loss: 18.2232\n",
            "Epoch 46/700\n",
            "15/15 [==============================] - 0s 191us/step - loss: 18.0248\n",
            "Epoch 47/700\n",
            "15/15 [==============================] - 0s 202us/step - loss: 17.8286\n",
            "Epoch 48/700\n",
            "15/15 [==============================] - 0s 257us/step - loss: 17.6345\n",
            "Epoch 49/700\n",
            "15/15 [==============================] - 0s 291us/step - loss: 17.4425\n",
            "Epoch 50/700\n",
            "15/15 [==============================] - 0s 351us/step - loss: 17.2526\n",
            "Epoch 51/700\n",
            "15/15 [==============================] - 0s 311us/step - loss: 17.0648\n",
            "Epoch 52/700\n",
            "15/15 [==============================] - 0s 367us/step - loss: 16.8790\n",
            "Epoch 53/700\n",
            "15/15 [==============================] - 0s 290us/step - loss: 16.6952\n",
            "Epoch 54/700\n",
            "15/15 [==============================] - 0s 358us/step - loss: 16.5134\n",
            "Epoch 55/700\n",
            "15/15 [==============================] - 0s 307us/step - loss: 16.3336\n",
            "Epoch 56/700\n",
            "15/15 [==============================] - 0s 305us/step - loss: 16.1558\n",
            "Epoch 57/700\n",
            "15/15 [==============================] - 0s 323us/step - loss: 15.9799\n",
            "Epoch 58/700\n",
            "15/15 [==============================] - 0s 353us/step - loss: 15.8059\n",
            "Epoch 59/700\n",
            "15/15 [==============================] - 0s 264us/step - loss: 15.6339\n",
            "Epoch 60/700\n",
            "15/15 [==============================] - 0s 316us/step - loss: 15.4636\n",
            "Epoch 61/700\n",
            "15/15 [==============================] - 0s 339us/step - loss: 15.2953\n",
            "Epoch 62/700\n",
            "15/15 [==============================] - 0s 250us/step - loss: 15.1288\n",
            "Epoch 63/700\n",
            "15/15 [==============================] - 0s 325us/step - loss: 14.9640\n",
            "Epoch 64/700\n",
            "15/15 [==============================] - 0s 223us/step - loss: 14.8011\n",
            "Epoch 65/700\n",
            "15/15 [==============================] - 0s 246us/step - loss: 14.6400\n",
            "Epoch 66/700\n",
            "15/15 [==============================] - 0s 330us/step - loss: 14.4806\n",
            "Epoch 67/700\n",
            "15/15 [==============================] - 0s 200us/step - loss: 14.3229\n",
            "Epoch 68/700\n",
            "15/15 [==============================] - 0s 241us/step - loss: 14.1670\n",
            "Epoch 69/700\n",
            "15/15 [==============================] - 0s 216us/step - loss: 14.0128\n",
            "Epoch 70/700\n",
            "15/15 [==============================] - 0s 176us/step - loss: 13.8602\n",
            "Epoch 71/700\n",
            "15/15 [==============================] - 0s 229us/step - loss: 13.7093\n",
            "Epoch 72/700\n",
            "15/15 [==============================] - 0s 270us/step - loss: 13.5600\n",
            "Epoch 73/700\n",
            "15/15 [==============================] - 0s 253us/step - loss: 13.4124\n",
            "Epoch 74/700\n",
            "15/15 [==============================] - 0s 281us/step - loss: 13.2664\n",
            "Epoch 75/700\n",
            "15/15 [==============================] - 0s 397us/step - loss: 13.1219\n",
            "Epoch 76/700\n",
            "15/15 [==============================] - 0s 357us/step - loss: 12.9791\n",
            "Epoch 77/700\n",
            "15/15 [==============================] - 0s 289us/step - loss: 12.8378\n",
            "Epoch 78/700\n",
            "15/15 [==============================] - 0s 273us/step - loss: 12.6980\n",
            "Epoch 79/700\n",
            "15/15 [==============================] - 0s 267us/step - loss: 12.5597\n",
            "Epoch 80/700\n",
            "15/15 [==============================] - 0s 278us/step - loss: 12.4230\n",
            "Epoch 81/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 12.2878\n",
            "Epoch 82/700\n",
            "15/15 [==============================] - 0s 268us/step - loss: 12.1540\n",
            "Epoch 83/700\n",
            "15/15 [==============================] - 0s 262us/step - loss: 12.0216\n",
            "Epoch 84/700\n",
            "15/15 [==============================] - 0s 259us/step - loss: 11.8908\n",
            "Epoch 85/700\n",
            "15/15 [==============================] - 0s 276us/step - loss: 11.7613\n",
            "Epoch 86/700\n",
            "15/15 [==============================] - 0s 277us/step - loss: 11.6333\n",
            "Epoch 87/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 11.5066\n",
            "Epoch 88/700\n",
            "15/15 [==============================] - 0s 305us/step - loss: 11.3813\n",
            "Epoch 89/700\n",
            "15/15 [==============================] - 0s 267us/step - loss: 11.2574\n",
            "Epoch 90/700\n",
            "15/15 [==============================] - 0s 321us/step - loss: 11.1348\n",
            "Epoch 91/700\n",
            "15/15 [==============================] - 0s 328us/step - loss: 11.0136\n",
            "Epoch 92/700\n",
            "15/15 [==============================] - 0s 267us/step - loss: 10.8937\n",
            "Epoch 93/700\n",
            "15/15 [==============================] - 0s 336us/step - loss: 10.7751\n",
            "Epoch 94/700\n",
            "15/15 [==============================] - 0s 294us/step - loss: 10.6578\n",
            "Epoch 95/700\n",
            "15/15 [==============================] - 0s 330us/step - loss: 10.5418\n",
            "Epoch 96/700\n",
            "15/15 [==============================] - 0s 303us/step - loss: 10.4270\n",
            "Epoch 97/700\n",
            "15/15 [==============================] - 0s 305us/step - loss: 10.3135\n",
            "Epoch 98/700\n",
            "15/15 [==============================] - 0s 288us/step - loss: 10.2012\n",
            "Epoch 99/700\n",
            "15/15 [==============================] - 0s 310us/step - loss: 10.0901\n",
            "Epoch 100/700\n",
            "15/15 [==============================] - 0s 250us/step - loss: 9.9803\n",
            "Epoch 101/700\n",
            "15/15 [==============================] - 0s 294us/step - loss: 9.8716\n",
            "Epoch 102/700\n",
            "15/15 [==============================] - 0s 297us/step - loss: 9.7641\n",
            "Epoch 103/700\n",
            "15/15 [==============================] - 0s 366us/step - loss: 9.6578\n",
            "Epoch 104/700\n",
            "15/15 [==============================] - 0s 312us/step - loss: 9.5527\n",
            "Epoch 105/700\n",
            "15/15 [==============================] - 0s 281us/step - loss: 9.4487\n",
            "Epoch 106/700\n",
            "15/15 [==============================] - 0s 300us/step - loss: 9.3458\n",
            "Epoch 107/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 9.2440\n",
            "Epoch 108/700\n",
            "15/15 [==============================] - 0s 293us/step - loss: 9.1434\n",
            "Epoch 109/700\n",
            "15/15 [==============================] - 0s 319us/step - loss: 9.0438\n",
            "Epoch 110/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 8.9454\n",
            "Epoch 111/700\n",
            "15/15 [==============================] - 0s 271us/step - loss: 8.8480\n",
            "Epoch 112/700\n",
            "15/15 [==============================] - 0s 299us/step - loss: 8.7517\n",
            "Epoch 113/700\n",
            "15/15 [==============================] - 0s 299us/step - loss: 8.6564\n",
            "Epoch 114/700\n",
            "15/15 [==============================] - 0s 309us/step - loss: 8.5621\n",
            "Epoch 115/700\n",
            "15/15 [==============================] - 0s 314us/step - loss: 8.4689\n",
            "Epoch 116/700\n",
            "15/15 [==============================] - 0s 300us/step - loss: 8.3767\n",
            "Epoch 117/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 8.2855\n",
            "Epoch 118/700\n",
            "15/15 [==============================] - 0s 271us/step - loss: 8.1953\n",
            "Epoch 119/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 8.1061\n",
            "Epoch 120/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 8.0178\n",
            "Epoch 121/700\n",
            "15/15 [==============================] - 0s 275us/step - loss: 7.9305\n",
            "Epoch 122/700\n",
            "15/15 [==============================] - 0s 261us/step - loss: 7.8442\n",
            "Epoch 123/700\n",
            "15/15 [==============================] - 0s 294us/step - loss: 7.7588\n",
            "Epoch 124/700\n",
            "15/15 [==============================] - 0s 457us/step - loss: 7.6743\n",
            "Epoch 125/700\n",
            "15/15 [==============================] - 0s 186us/step - loss: 7.5908\n",
            "Epoch 126/700\n",
            "15/15 [==============================] - 0s 742us/step - loss: 7.5081\n",
            "Epoch 127/700\n",
            "15/15 [==============================] - 0s 184us/step - loss: 7.4264\n",
            "Epoch 128/700\n",
            "15/15 [==============================] - 0s 247us/step - loss: 7.3455\n",
            "Epoch 129/700\n",
            "15/15 [==============================] - 0s 207us/step - loss: 7.2655\n",
            "Epoch 130/700\n",
            "15/15 [==============================] - 0s 181us/step - loss: 7.1864\n",
            "Epoch 131/700\n",
            "15/15 [==============================] - 0s 167us/step - loss: 7.1082\n",
            "Epoch 132/700\n",
            "15/15 [==============================] - 0s 203us/step - loss: 7.0308\n",
            "Epoch 133/700\n",
            "15/15 [==============================] - 0s 185us/step - loss: 6.9543\n",
            "Epoch 134/700\n",
            "15/15 [==============================] - 0s 242us/step - loss: 6.8785\n",
            "Epoch 135/700\n",
            "15/15 [==============================] - 0s 283us/step - loss: 6.8037\n",
            "Epoch 136/700\n",
            "15/15 [==============================] - 0s 292us/step - loss: 6.7296\n",
            "Epoch 137/700\n",
            "15/15 [==============================] - 0s 295us/step - loss: 6.6563\n",
            "Epoch 138/700\n",
            "15/15 [==============================] - 0s 338us/step - loss: 6.5838\n",
            "Epoch 139/700\n",
            "15/15 [==============================] - 0s 387us/step - loss: 6.5122\n",
            "Epoch 140/700\n",
            "15/15 [==============================] - 0s 283us/step - loss: 6.4413\n",
            "Epoch 141/700\n",
            "15/15 [==============================] - 0s 321us/step - loss: 6.3711\n",
            "Epoch 142/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 6.3018\n",
            "Epoch 143/700\n",
            "15/15 [==============================] - 0s 340us/step - loss: 6.2332\n",
            "Epoch 144/700\n",
            "15/15 [==============================] - 0s 261us/step - loss: 6.1653\n",
            "Epoch 145/700\n",
            "15/15 [==============================] - 0s 307us/step - loss: 6.0982\n",
            "Epoch 146/700\n",
            "15/15 [==============================] - 0s 334us/step - loss: 6.0318\n",
            "Epoch 147/700\n",
            "15/15 [==============================] - 0s 286us/step - loss: 5.9661\n",
            "Epoch 148/700\n",
            "15/15 [==============================] - 0s 309us/step - loss: 5.9012\n",
            "Epoch 149/700\n",
            "15/15 [==============================] - 0s 314us/step - loss: 5.8369\n",
            "Epoch 150/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 5.7734\n",
            "Epoch 151/700\n",
            "15/15 [==============================] - 0s 341us/step - loss: 5.7105\n",
            "Epoch 152/700\n",
            "15/15 [==============================] - 0s 259us/step - loss: 5.6483\n",
            "Epoch 153/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 5.5868\n",
            "Epoch 154/700\n",
            "15/15 [==============================] - 0s 335us/step - loss: 5.5260\n",
            "Epoch 155/700\n",
            "15/15 [==============================] - 0s 308us/step - loss: 5.4658\n",
            "Epoch 156/700\n",
            "15/15 [==============================] - 0s 211us/step - loss: 5.4063\n",
            "Epoch 157/700\n",
            "15/15 [==============================] - 0s 207us/step - loss: 5.3475\n",
            "Epoch 158/700\n",
            "15/15 [==============================] - 0s 327us/step - loss: 5.2893\n",
            "Epoch 159/700\n",
            "15/15 [==============================] - 0s 322us/step - loss: 5.2317\n",
            "Epoch 160/700\n",
            "15/15 [==============================] - 0s 311us/step - loss: 5.1747\n",
            "Epoch 161/700\n",
            "15/15 [==============================] - 0s 276us/step - loss: 5.1184\n",
            "Epoch 162/700\n",
            "15/15 [==============================] - 0s 287us/step - loss: 5.0626\n",
            "Epoch 163/700\n",
            "15/15 [==============================] - 0s 266us/step - loss: 5.0075\n",
            "Epoch 164/700\n",
            "15/15 [==============================] - 0s 299us/step - loss: 4.9530\n",
            "Epoch 165/700\n",
            "15/15 [==============================] - 0s 288us/step - loss: 4.8991\n",
            "Epoch 166/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 4.8457\n",
            "Epoch 167/700\n",
            "15/15 [==============================] - 0s 275us/step - loss: 4.7930\n",
            "Epoch 168/700\n",
            "15/15 [==============================] - 0s 266us/step - loss: 4.7408\n",
            "Epoch 169/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 4.6892\n",
            "Epoch 170/700\n",
            "15/15 [==============================] - 0s 308us/step - loss: 4.6381\n",
            "Epoch 171/700\n",
            "15/15 [==============================] - 0s 299us/step - loss: 4.5876\n",
            "Epoch 172/700\n",
            "15/15 [==============================] - 0s 264us/step - loss: 4.5377\n",
            "Epoch 173/700\n",
            "15/15 [==============================] - 0s 229us/step - loss: 4.4883\n",
            "Epoch 174/700\n",
            "15/15 [==============================] - 0s 258us/step - loss: 4.4394\n",
            "Epoch 175/700\n",
            "15/15 [==============================] - 0s 283us/step - loss: 4.3911\n",
            "Epoch 176/700\n",
            "15/15 [==============================] - 0s 225us/step - loss: 4.3433\n",
            "Epoch 177/700\n",
            "15/15 [==============================] - 0s 307us/step - loss: 4.2960\n",
            "Epoch 178/700\n",
            "15/15 [==============================] - 0s 285us/step - loss: 4.2492\n",
            "Epoch 179/700\n",
            "15/15 [==============================] - 0s 269us/step - loss: 4.2030\n",
            "Epoch 180/700\n",
            "15/15 [==============================] - 0s 370us/step - loss: 4.1572\n",
            "Epoch 181/700\n",
            "15/15 [==============================] - 0s 277us/step - loss: 4.1119\n",
            "Epoch 182/700\n",
            "15/15 [==============================] - 0s 322us/step - loss: 4.0672\n",
            "Epoch 183/700\n",
            "15/15 [==============================] - 0s 280us/step - loss: 4.0229\n",
            "Epoch 184/700\n",
            "15/15 [==============================] - 0s 281us/step - loss: 3.9791\n",
            "Epoch 185/700\n",
            "15/15 [==============================] - 0s 317us/step - loss: 3.9358\n",
            "Epoch 186/700\n",
            "15/15 [==============================] - 0s 275us/step - loss: 3.8929\n",
            "Epoch 187/700\n",
            "15/15 [==============================] - 0s 324us/step - loss: 3.8505\n",
            "Epoch 188/700\n",
            "15/15 [==============================] - 0s 324us/step - loss: 3.8086\n",
            "Epoch 189/700\n",
            "15/15 [==============================] - 0s 331us/step - loss: 3.7671\n",
            "Epoch 190/700\n",
            "15/15 [==============================] - 0s 327us/step - loss: 3.7261\n",
            "Epoch 191/700\n",
            "15/15 [==============================] - 0s 312us/step - loss: 3.6856\n",
            "Epoch 192/700\n",
            "15/15 [==============================] - 0s 314us/step - loss: 3.6454\n",
            "Epoch 193/700\n",
            "15/15 [==============================] - 0s 359us/step - loss: 3.6058\n",
            "Epoch 194/700\n",
            "15/15 [==============================] - 0s 328us/step - loss: 3.5665\n",
            "Epoch 195/700\n",
            "15/15 [==============================] - 0s 295us/step - loss: 3.5277\n",
            "Epoch 196/700\n",
            "15/15 [==============================] - 0s 299us/step - loss: 3.4893\n",
            "Epoch 197/700\n",
            "15/15 [==============================] - 0s 322us/step - loss: 3.4513\n",
            "Epoch 198/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 3.4137\n",
            "Epoch 199/700\n",
            "15/15 [==============================] - 0s 334us/step - loss: 3.3765\n",
            "Epoch 200/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 3.3398\n",
            "Epoch 201/700\n",
            "15/15 [==============================] - 0s 295us/step - loss: 3.3034\n",
            "Epoch 202/700\n",
            "15/15 [==============================] - 0s 280us/step - loss: 3.2674\n",
            "Epoch 203/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 3.2319\n",
            "Epoch 204/700\n",
            "15/15 [==============================] - 0s 330us/step - loss: 3.1967\n",
            "Epoch 205/700\n",
            "15/15 [==============================] - 0s 316us/step - loss: 3.1619\n",
            "Epoch 206/700\n",
            "15/15 [==============================] - 0s 273us/step - loss: 3.1274\n",
            "Epoch 207/700\n",
            "15/15 [==============================] - 0s 292us/step - loss: 3.0934\n",
            "Epoch 208/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 3.0597\n",
            "Epoch 209/700\n",
            "15/15 [==============================] - 0s 309us/step - loss: 3.0264\n",
            "Epoch 210/700\n",
            "15/15 [==============================] - 0s 300us/step - loss: 2.9935\n",
            "Epoch 211/700\n",
            "15/15 [==============================] - 0s 276us/step - loss: 2.9609\n",
            "Epoch 212/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 2.9286\n",
            "Epoch 213/700\n",
            "15/15 [==============================] - 0s 263us/step - loss: 2.8967\n",
            "Epoch 214/700\n",
            "15/15 [==============================] - 0s 307us/step - loss: 2.8652\n",
            "Epoch 215/700\n",
            "15/15 [==============================] - 0s 217us/step - loss: 2.8340\n",
            "Epoch 216/700\n",
            "15/15 [==============================] - 0s 188us/step - loss: 2.8032\n",
            "Epoch 217/700\n",
            "15/15 [==============================] - 0s 309us/step - loss: 2.7726\n",
            "Epoch 218/700\n",
            "15/15 [==============================] - 0s 285us/step - loss: 2.7425\n",
            "Epoch 219/700\n",
            "15/15 [==============================] - 0s 333us/step - loss: 2.7126\n",
            "Epoch 220/700\n",
            "15/15 [==============================] - 0s 280us/step - loss: 2.6831\n",
            "Epoch 221/700\n",
            "15/15 [==============================] - 0s 291us/step - loss: 2.6538\n",
            "Epoch 222/700\n",
            "15/15 [==============================] - 0s 311us/step - loss: 2.6250\n",
            "Epoch 223/700\n",
            "15/15 [==============================] - 0s 290us/step - loss: 2.5964\n",
            "Epoch 224/700\n",
            "15/15 [==============================] - 0s 319us/step - loss: 2.5681\n",
            "Epoch 225/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 2.5401\n",
            "Epoch 226/700\n",
            "15/15 [==============================] - 0s 291us/step - loss: 2.5125\n",
            "Epoch 227/700\n",
            "15/15 [==============================] - 0s 297us/step - loss: 2.4851\n",
            "Epoch 228/700\n",
            "15/15 [==============================] - 0s 301us/step - loss: 2.4581\n",
            "Epoch 229/700\n",
            "15/15 [==============================] - 0s 291us/step - loss: 2.4313\n",
            "Epoch 230/700\n",
            "15/15 [==============================] - 0s 303us/step - loss: 2.4049\n",
            "Epoch 231/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 2.3787\n",
            "Epoch 232/700\n",
            "15/15 [==============================] - 0s 308us/step - loss: 2.3528\n",
            "Epoch 233/700\n",
            "15/15 [==============================] - 0s 248us/step - loss: 2.3272\n",
            "Epoch 234/700\n",
            "15/15 [==============================] - 0s 226us/step - loss: 2.3018\n",
            "Epoch 235/700\n",
            "15/15 [==============================] - 0s 224us/step - loss: 2.2768\n",
            "Epoch 236/700\n",
            "15/15 [==============================] - 0s 221us/step - loss: 2.2520\n",
            "Epoch 237/700\n",
            "15/15 [==============================] - 0s 190us/step - loss: 2.2275\n",
            "Epoch 238/700\n",
            "15/15 [==============================] - 0s 300us/step - loss: 2.2032\n",
            "Epoch 239/700\n",
            "15/15 [==============================] - 0s 270us/step - loss: 2.1792\n",
            "Epoch 240/700\n",
            "15/15 [==============================] - 0s 348us/step - loss: 2.1555\n",
            "Epoch 241/700\n",
            "15/15 [==============================] - 0s 281us/step - loss: 2.1320\n",
            "Epoch 242/700\n",
            "15/15 [==============================] - 0s 301us/step - loss: 2.1088\n",
            "Epoch 243/700\n",
            "15/15 [==============================] - 0s 320us/step - loss: 2.0858\n",
            "Epoch 244/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 2.0631\n",
            "Epoch 245/700\n",
            "15/15 [==============================] - 0s 300us/step - loss: 2.0407\n",
            "Epoch 246/700\n",
            "15/15 [==============================] - 0s 275us/step - loss: 2.0185\n",
            "Epoch 247/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 1.9965\n",
            "Epoch 248/700\n",
            "15/15 [==============================] - 0s 281us/step - loss: 1.9747\n",
            "Epoch 249/700\n",
            "15/15 [==============================] - 0s 297us/step - loss: 1.9532\n",
            "Epoch 250/700\n",
            "15/15 [==============================] - 0s 272us/step - loss: 1.9320\n",
            "Epoch 251/700\n",
            "15/15 [==============================] - 0s 281us/step - loss: 1.9109\n",
            "Epoch 252/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 1.8901\n",
            "Epoch 253/700\n",
            "15/15 [==============================] - 0s 344us/step - loss: 1.8696\n",
            "Epoch 254/700\n",
            "15/15 [==============================] - 0s 293us/step - loss: 1.8492\n",
            "Epoch 255/700\n",
            "15/15 [==============================] - 0s 307us/step - loss: 1.8291\n",
            "Epoch 256/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 1.8092\n",
            "Epoch 257/700\n",
            "15/15 [==============================] - 0s 291us/step - loss: 1.7895\n",
            "Epoch 258/700\n",
            "15/15 [==============================] - 0s 248us/step - loss: 1.7700\n",
            "Epoch 259/700\n",
            "15/15 [==============================] - 0s 401us/step - loss: 1.7507\n",
            "Epoch 260/700\n",
            "15/15 [==============================] - 0s 365us/step - loss: 1.7317\n",
            "Epoch 261/700\n",
            "15/15 [==============================] - 0s 574us/step - loss: 1.7128\n",
            "Epoch 262/700\n",
            "15/15 [==============================] - 0s 389us/step - loss: 1.6942\n",
            "Epoch 263/700\n",
            "15/15 [==============================] - 0s 552us/step - loss: 1.6757\n",
            "Epoch 264/700\n",
            "15/15 [==============================] - 0s 460us/step - loss: 1.6575\n",
            "Epoch 265/700\n",
            "15/15 [==============================] - 0s 375us/step - loss: 1.6394\n",
            "Epoch 266/700\n",
            "15/15 [==============================] - 0s 361us/step - loss: 1.6216\n",
            "Epoch 267/700\n",
            "15/15 [==============================] - 0s 233us/step - loss: 1.6039\n",
            "Epoch 268/700\n",
            "15/15 [==============================] - 0s 326us/step - loss: 1.5865\n",
            "Epoch 269/700\n",
            "15/15 [==============================] - 0s 242us/step - loss: 1.5692\n",
            "Epoch 270/700\n",
            "15/15 [==============================] - 0s 265us/step - loss: 1.5521\n",
            "Epoch 271/700\n",
            "15/15 [==============================] - 0s 246us/step - loss: 1.5352\n",
            "Epoch 272/700\n",
            "15/15 [==============================] - 0s 200us/step - loss: 1.5185\n",
            "Epoch 273/700\n",
            "15/15 [==============================] - 0s 207us/step - loss: 1.5019\n",
            "Epoch 274/700\n",
            "15/15 [==============================] - 0s 223us/step - loss: 1.4856\n",
            "Epoch 275/700\n",
            "15/15 [==============================] - 0s 180us/step - loss: 1.4694\n",
            "Epoch 276/700\n",
            "15/15 [==============================] - 0s 225us/step - loss: 1.4534\n",
            "Epoch 277/700\n",
            "15/15 [==============================] - 0s 966us/step - loss: 1.4376\n",
            "Epoch 278/700\n",
            "15/15 [==============================] - 0s 280us/step - loss: 1.4219\n",
            "Epoch 279/700\n",
            "15/15 [==============================] - 0s 651us/step - loss: 1.4065\n",
            "Epoch 280/700\n",
            "15/15 [==============================] - 0s 417us/step - loss: 1.3912\n",
            "Epoch 281/700\n",
            "15/15 [==============================] - 0s 408us/step - loss: 1.3760\n",
            "Epoch 282/700\n",
            "15/15 [==============================] - 0s 381us/step - loss: 1.3610\n",
            "Epoch 283/700\n",
            "15/15 [==============================] - 0s 376us/step - loss: 1.3462\n",
            "Epoch 284/700\n",
            "15/15 [==============================] - 0s 334us/step - loss: 1.3316\n",
            "Epoch 285/700\n",
            "15/15 [==============================] - 0s 315us/step - loss: 1.3171\n",
            "Epoch 286/700\n",
            "15/15 [==============================] - 0s 283us/step - loss: 1.3027\n",
            "Epoch 287/700\n",
            "15/15 [==============================] - 0s 287us/step - loss: 1.2885\n",
            "Epoch 288/700\n",
            "15/15 [==============================] - 0s 327us/step - loss: 1.2745\n",
            "Epoch 289/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 1.2606\n",
            "Epoch 290/700\n",
            "15/15 [==============================] - 0s 333us/step - loss: 1.2469\n",
            "Epoch 291/700\n",
            "15/15 [==============================] - 0s 280us/step - loss: 1.2333\n",
            "Epoch 292/700\n",
            "15/15 [==============================] - 0s 288us/step - loss: 1.2199\n",
            "Epoch 293/700\n",
            "15/15 [==============================] - 0s 257us/step - loss: 1.2066\n",
            "Epoch 294/700\n",
            "15/15 [==============================] - 0s 245us/step - loss: 1.1935\n",
            "Epoch 295/700\n",
            "15/15 [==============================] - 0s 254us/step - loss: 1.1805\n",
            "Epoch 296/700\n",
            "15/15 [==============================] - 0s 199us/step - loss: 1.1676\n",
            "Epoch 297/700\n",
            "15/15 [==============================] - 0s 186us/step - loss: 1.1549\n",
            "Epoch 298/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 1.1423\n",
            "Epoch 299/700\n",
            "15/15 [==============================] - 0s 289us/step - loss: 1.1299\n",
            "Epoch 300/700\n",
            "15/15 [==============================] - 0s 291us/step - loss: 1.1176\n",
            "Epoch 301/700\n",
            "15/15 [==============================] - 0s 273us/step - loss: 1.1054\n",
            "Epoch 302/700\n",
            "15/15 [==============================] - 0s 316us/step - loss: 1.0934\n",
            "Epoch 303/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 1.0815\n",
            "Epoch 304/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 1.0697\n",
            "Epoch 305/700\n",
            "15/15 [==============================] - 0s 181us/step - loss: 1.0581\n",
            "Epoch 306/700\n",
            "15/15 [==============================] - 0s 281us/step - loss: 1.0466\n",
            "Epoch 307/700\n",
            "15/15 [==============================] - 0s 308us/step - loss: 1.0352\n",
            "Epoch 308/700\n",
            "15/15 [==============================] - 0s 312us/step - loss: 1.0239\n",
            "Epoch 309/700\n",
            "15/15 [==============================] - 0s 268us/step - loss: 1.0128\n",
            "Epoch 310/700\n",
            "15/15 [==============================] - 0s 314us/step - loss: 1.0017\n",
            "Epoch 311/700\n",
            "15/15 [==============================] - 0s 322us/step - loss: 0.9908\n",
            "Epoch 312/700\n",
            "15/15 [==============================] - 0s 271us/step - loss: 0.9800\n",
            "Epoch 313/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 0.9694\n",
            "Epoch 314/700\n",
            "15/15 [==============================] - 0s 247us/step - loss: 0.9588\n",
            "Epoch 315/700\n",
            "15/15 [==============================] - 0s 310us/step - loss: 0.9484\n",
            "Epoch 316/700\n",
            "15/15 [==============================] - 0s 261us/step - loss: 0.9380\n",
            "Epoch 317/700\n",
            "15/15 [==============================] - 0s 309us/step - loss: 0.9278\n",
            "Epoch 318/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 0.9177\n",
            "Epoch 319/700\n",
            "15/15 [==============================] - 0s 287us/step - loss: 0.9077\n",
            "Epoch 320/700\n",
            "15/15 [==============================] - 0s 293us/step - loss: 0.8979\n",
            "Epoch 321/700\n",
            "15/15 [==============================] - 0s 303us/step - loss: 0.8881\n",
            "Epoch 322/700\n",
            "15/15 [==============================] - 0s 310us/step - loss: 0.8784\n",
            "Epoch 323/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 0.8688\n",
            "Epoch 324/700\n",
            "15/15 [==============================] - 0s 312us/step - loss: 0.8594\n",
            "Epoch 325/700\n",
            "15/15 [==============================] - 0s 222us/step - loss: 0.8500\n",
            "Epoch 326/700\n",
            "15/15 [==============================] - 0s 195us/step - loss: 0.8408\n",
            "Epoch 327/700\n",
            "15/15 [==============================] - 0s 217us/step - loss: 0.8316\n",
            "Epoch 328/700\n",
            "15/15 [==============================] - 0s 199us/step - loss: 0.8226\n",
            "Epoch 329/700\n",
            "15/15 [==============================] - 0s 309us/step - loss: 0.8136\n",
            "Epoch 330/700\n",
            "15/15 [==============================] - 0s 256us/step - loss: 0.8048\n",
            "Epoch 331/700\n",
            "15/15 [==============================] - 0s 418us/step - loss: 0.7960\n",
            "Epoch 332/700\n",
            "15/15 [==============================] - 0s 415us/step - loss: 0.7873\n",
            "Epoch 333/700\n",
            "15/15 [==============================] - 0s 399us/step - loss: 0.7788\n",
            "Epoch 334/700\n",
            "15/15 [==============================] - 0s 489us/step - loss: 0.7703\n",
            "Epoch 335/700\n",
            "15/15 [==============================] - 0s 419us/step - loss: 0.7619\n",
            "Epoch 336/700\n",
            "15/15 [==============================] - 0s 450us/step - loss: 0.7536\n",
            "Epoch 337/700\n",
            "15/15 [==============================] - 0s 873us/step - loss: 0.7454\n",
            "Epoch 338/700\n",
            "15/15 [==============================] - 0s 470us/step - loss: 0.7373\n",
            "Epoch 339/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 0.7292\n",
            "Epoch 340/700\n",
            "15/15 [==============================] - 0s 207us/step - loss: 0.7213\n",
            "Epoch 341/700\n",
            "15/15 [==============================] - 0s 275us/step - loss: 0.7135\n",
            "Epoch 342/700\n",
            "15/15 [==============================] - 0s 264us/step - loss: 0.7057\n",
            "Epoch 343/700\n",
            "15/15 [==============================] - 0s 266us/step - loss: 0.6980\n",
            "Epoch 344/700\n",
            "15/15 [==============================] - 0s 273us/step - loss: 0.6904\n",
            "Epoch 345/700\n",
            "15/15 [==============================] - 0s 266us/step - loss: 0.6829\n",
            "Epoch 346/700\n",
            "15/15 [==============================] - 0s 272us/step - loss: 0.6755\n",
            "Epoch 347/700\n",
            "15/15 [==============================] - 0s 286us/step - loss: 0.6681\n",
            "Epoch 348/700\n",
            "15/15 [==============================] - 0s 301us/step - loss: 0.6608\n",
            "Epoch 349/700\n",
            "15/15 [==============================] - 0s 300us/step - loss: 0.6536\n",
            "Epoch 350/700\n",
            "15/15 [==============================] - 0s 235us/step - loss: 0.6465\n",
            "Epoch 351/700\n",
            "15/15 [==============================] - 0s 281us/step - loss: 0.6395\n",
            "Epoch 352/700\n",
            "15/15 [==============================] - 0s 300us/step - loss: 0.6325\n",
            "Epoch 353/700\n",
            "15/15 [==============================] - 0s 253us/step - loss: 0.6256\n",
            "Epoch 354/700\n",
            "15/15 [==============================] - 0s 214us/step - loss: 0.6188\n",
            "Epoch 355/700\n",
            "15/15 [==============================] - 0s 295us/step - loss: 0.6121\n",
            "Epoch 356/700\n",
            "15/15 [==============================] - 0s 212us/step - loss: 0.6054\n",
            "Epoch 357/700\n",
            "15/15 [==============================] - 0s 200us/step - loss: 0.5988\n",
            "Epoch 358/700\n",
            "15/15 [==============================] - 0s 237us/step - loss: 0.5923\n",
            "Epoch 359/700\n",
            "15/15 [==============================] - 0s 274us/step - loss: 0.5859\n",
            "Epoch 360/700\n",
            "15/15 [==============================] - 0s 547us/step - loss: 0.5795\n",
            "Epoch 361/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 0.5732\n",
            "Epoch 362/700\n",
            "15/15 [==============================] - 0s 249us/step - loss: 0.5669\n",
            "Epoch 363/700\n",
            "15/15 [==============================] - 0s 347us/step - loss: 0.5608\n",
            "Epoch 364/700\n",
            "15/15 [==============================] - 0s 283us/step - loss: 0.5547\n",
            "Epoch 365/700\n",
            "15/15 [==============================] - 0s 349us/step - loss: 0.5486\n",
            "Epoch 366/700\n",
            "15/15 [==============================] - 0s 257us/step - loss: 0.5426\n",
            "Epoch 367/700\n",
            "15/15 [==============================] - 0s 222us/step - loss: 0.5367\n",
            "Epoch 368/700\n",
            "15/15 [==============================] - 0s 347us/step - loss: 0.5309\n",
            "Epoch 369/700\n",
            "15/15 [==============================] - 0s 342us/step - loss: 0.5251\n",
            "Epoch 370/700\n",
            "15/15 [==============================] - 0s 395us/step - loss: 0.5194\n",
            "Epoch 371/700\n",
            "15/15 [==============================] - 0s 402us/step - loss: 0.5137\n",
            "Epoch 372/700\n",
            "15/15 [==============================] - 0s 439us/step - loss: 0.5081\n",
            "Epoch 373/700\n",
            "15/15 [==============================] - 0s 351us/step - loss: 0.5026\n",
            "Epoch 374/700\n",
            "15/15 [==============================] - 0s 355us/step - loss: 0.4971\n",
            "Epoch 375/700\n",
            "15/15 [==============================] - 0s 384us/step - loss: 0.4917\n",
            "Epoch 376/700\n",
            "15/15 [==============================] - 0s 423us/step - loss: 0.4864\n",
            "Epoch 377/700\n",
            "15/15 [==============================] - 0s 406us/step - loss: 0.4811\n",
            "Epoch 378/700\n",
            "15/15 [==============================] - 0s 380us/step - loss: 0.4758\n",
            "Epoch 379/700\n",
            "15/15 [==============================] - 0s 372us/step - loss: 0.4707\n",
            "Epoch 380/700\n",
            "15/15 [==============================] - 0s 353us/step - loss: 0.4655\n",
            "Epoch 381/700\n",
            "15/15 [==============================] - 0s 376us/step - loss: 0.4605\n",
            "Epoch 382/700\n",
            "15/15 [==============================] - 0s 459us/step - loss: 0.4555\n",
            "Epoch 383/700\n",
            "15/15 [==============================] - 0s 381us/step - loss: 0.4505\n",
            "Epoch 384/700\n",
            "15/15 [==============================] - 0s 435us/step - loss: 0.4456\n",
            "Epoch 385/700\n",
            "15/15 [==============================] - 0s 369us/step - loss: 0.4407\n",
            "Epoch 386/700\n",
            "15/15 [==============================] - 0s 380us/step - loss: 0.4359\n",
            "Epoch 387/700\n",
            "15/15 [==============================] - 0s 413us/step - loss: 0.4312\n",
            "Epoch 388/700\n",
            "15/15 [==============================] - 0s 383us/step - loss: 0.4265\n",
            "Epoch 389/700\n",
            "15/15 [==============================] - 0s 352us/step - loss: 0.4219\n",
            "Epoch 390/700\n",
            "15/15 [==============================] - 0s 372us/step - loss: 0.4173\n",
            "Epoch 391/700\n",
            "15/15 [==============================] - 0s 346us/step - loss: 0.4127\n",
            "Epoch 392/700\n",
            "15/15 [==============================] - 0s 361us/step - loss: 0.4082\n",
            "Epoch 393/700\n",
            "15/15 [==============================] - 0s 440us/step - loss: 0.4038\n",
            "Epoch 394/700\n",
            "15/15 [==============================] - 0s 344us/step - loss: 0.3994\n",
            "Epoch 395/700\n",
            "15/15 [==============================] - 0s 364us/step - loss: 0.3950\n",
            "Epoch 396/700\n",
            "15/15 [==============================] - 0s 332us/step - loss: 0.3907\n",
            "Epoch 397/700\n",
            "15/15 [==============================] - 0s 357us/step - loss: 0.3865\n",
            "Epoch 398/700\n",
            "15/15 [==============================] - 0s 344us/step - loss: 0.3823\n",
            "Epoch 399/700\n",
            "15/15 [==============================] - 0s 409us/step - loss: 0.3781\n",
            "Epoch 400/700\n",
            "15/15 [==============================] - 0s 315us/step - loss: 0.3740\n",
            "Epoch 401/700\n",
            "15/15 [==============================] - 0s 255us/step - loss: 0.3699\n",
            "Epoch 402/700\n",
            "15/15 [==============================] - 0s 189us/step - loss: 0.3659\n",
            "Epoch 403/700\n",
            "15/15 [==============================] - 0s 249us/step - loss: 0.3619\n",
            "Epoch 404/700\n",
            "15/15 [==============================] - 0s 236us/step - loss: 0.3580\n",
            "Epoch 405/700\n",
            "15/15 [==============================] - 0s 229us/step - loss: 0.3541\n",
            "Epoch 406/700\n",
            "15/15 [==============================] - 0s 223us/step - loss: 0.3502\n",
            "Epoch 407/700\n",
            "15/15 [==============================] - 0s 268us/step - loss: 0.3464\n",
            "Epoch 408/700\n",
            "15/15 [==============================] - 0s 212us/step - loss: 0.3426\n",
            "Epoch 409/700\n",
            "15/15 [==============================] - 0s 227us/step - loss: 0.3389\n",
            "Epoch 410/700\n",
            "15/15 [==============================] - 0s 556us/step - loss: 0.3352\n",
            "Epoch 411/700\n",
            "15/15 [==============================] - 0s 426us/step - loss: 0.3316\n",
            "Epoch 412/700\n",
            "15/15 [==============================] - 0s 402us/step - loss: 0.3280\n",
            "Epoch 413/700\n",
            "15/15 [==============================] - 0s 590us/step - loss: 0.3244\n",
            "Epoch 414/700\n",
            "15/15 [==============================] - 0s 321us/step - loss: 0.3209\n",
            "Epoch 415/700\n",
            "15/15 [==============================] - 0s 340us/step - loss: 0.3174\n",
            "Epoch 416/700\n",
            "15/15 [==============================] - 0s 313us/step - loss: 0.3139\n",
            "Epoch 417/700\n",
            "15/15 [==============================] - 0s 388us/step - loss: 0.3105\n",
            "Epoch 418/700\n",
            "15/15 [==============================] - 0s 305us/step - loss: 0.3071\n",
            "Epoch 419/700\n",
            "15/15 [==============================] - 0s 227us/step - loss: 0.3038\n",
            "Epoch 420/700\n",
            "15/15 [==============================] - 0s 236us/step - loss: 0.3005\n",
            "Epoch 421/700\n",
            "15/15 [==============================] - 0s 277us/step - loss: 0.2972\n",
            "Epoch 422/700\n",
            "15/15 [==============================] - 0s 175us/step - loss: 0.2939\n",
            "Epoch 423/700\n",
            "15/15 [==============================] - 0s 200us/step - loss: 0.2907\n",
            "Epoch 424/700\n",
            "15/15 [==============================] - 0s 246us/step - loss: 0.2876\n",
            "Epoch 425/700\n",
            "15/15 [==============================] - 0s 222us/step - loss: 0.2845\n",
            "Epoch 426/700\n",
            "15/15 [==============================] - 0s 226us/step - loss: 0.2814\n",
            "Epoch 427/700\n",
            "15/15 [==============================] - 0s 162us/step - loss: 0.2783\n",
            "Epoch 428/700\n",
            "15/15 [==============================] - 0s 226us/step - loss: 0.2753\n",
            "Epoch 429/700\n",
            "15/15 [==============================] - 0s 374us/step - loss: 0.2723\n",
            "Epoch 430/700\n",
            "15/15 [==============================] - 0s 242us/step - loss: 0.2693\n",
            "Epoch 431/700\n",
            "15/15 [==============================] - 0s 203us/step - loss: 0.2664\n",
            "Epoch 432/700\n",
            "15/15 [==============================] - 0s 204us/step - loss: 0.2635\n",
            "Epoch 433/700\n",
            "15/15 [==============================] - 0s 255us/step - loss: 0.2606\n",
            "Epoch 434/700\n",
            "15/15 [==============================] - 0s 194us/step - loss: 0.2578\n",
            "Epoch 435/700\n",
            "15/15 [==============================] - 0s 224us/step - loss: 0.2550\n",
            "Epoch 436/700\n",
            "15/15 [==============================] - 0s 240us/step - loss: 0.2522\n",
            "Epoch 437/700\n",
            "15/15 [==============================] - 0s 181us/step - loss: 0.2494\n",
            "Epoch 438/700\n",
            "15/15 [==============================] - 0s 264us/step - loss: 0.2467\n",
            "Epoch 439/700\n",
            "15/15 [==============================] - 0s 242us/step - loss: 0.2440\n",
            "Epoch 440/700\n",
            "15/15 [==============================] - 0s 217us/step - loss: 0.2414\n",
            "Epoch 441/700\n",
            "15/15 [==============================] - 0s 199us/step - loss: 0.2387\n",
            "Epoch 442/700\n",
            "15/15 [==============================] - 0s 251us/step - loss: 0.2361\n",
            "Epoch 443/700\n",
            "15/15 [==============================] - 0s 254us/step - loss: 0.2336\n",
            "Epoch 444/700\n",
            "15/15 [==============================] - 0s 224us/step - loss: 0.2310\n",
            "Epoch 445/700\n",
            "15/15 [==============================] - 0s 204us/step - loss: 0.2285\n",
            "Epoch 446/700\n",
            "15/15 [==============================] - 0s 233us/step - loss: 0.2260\n",
            "Epoch 447/700\n",
            "15/15 [==============================] - 0s 216us/step - loss: 0.2236\n",
            "Epoch 448/700\n",
            "15/15 [==============================] - 0s 216us/step - loss: 0.2211\n",
            "Epoch 449/700\n",
            "15/15 [==============================] - 0s 341us/step - loss: 0.2187\n",
            "Epoch 450/700\n",
            "15/15 [==============================] - 0s 325us/step - loss: 0.2163\n",
            "Epoch 451/700\n",
            "15/15 [==============================] - 0s 411us/step - loss: 0.2140\n",
            "Epoch 452/700\n",
            "15/15 [==============================] - 0s 682us/step - loss: 0.2117\n",
            "Epoch 453/700\n",
            "15/15 [==============================] - 0s 249us/step - loss: 0.2094\n",
            "Epoch 454/700\n",
            "15/15 [==============================] - 0s 226us/step - loss: 0.2071\n",
            "Epoch 455/700\n",
            "15/15 [==============================] - 0s 244us/step - loss: 0.2048\n",
            "Epoch 456/700\n",
            "15/15 [==============================] - 0s 300us/step - loss: 0.2026\n",
            "Epoch 457/700\n",
            "15/15 [==============================] - 0s 399us/step - loss: 0.2004\n",
            "Epoch 458/700\n",
            "15/15 [==============================] - 0s 280us/step - loss: 0.1982\n",
            "Epoch 459/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 0.1960\n",
            "Epoch 460/700\n",
            "15/15 [==============================] - 0s 314us/step - loss: 0.1939\n",
            "Epoch 461/700\n",
            "15/15 [==============================] - 0s 331us/step - loss: 0.1918\n",
            "Epoch 462/700\n",
            "15/15 [==============================] - 0s 318us/step - loss: 0.1897\n",
            "Epoch 463/700\n",
            "15/15 [==============================] - 0s 325us/step - loss: 0.1876\n",
            "Epoch 464/700\n",
            "15/15 [==============================] - 0s 452us/step - loss: 0.1856\n",
            "Epoch 465/700\n",
            "15/15 [==============================] - 0s 306us/step - loss: 0.1836\n",
            "Epoch 466/700\n",
            "15/15 [==============================] - 0s 368us/step - loss: 0.1816\n",
            "Epoch 467/700\n",
            "15/15 [==============================] - 0s 366us/step - loss: 0.1796\n",
            "Epoch 468/700\n",
            "15/15 [==============================] - 0s 366us/step - loss: 0.1777\n",
            "Epoch 469/700\n",
            "15/15 [==============================] - 0s 356us/step - loss: 0.1757\n",
            "Epoch 470/700\n",
            "15/15 [==============================] - 0s 287us/step - loss: 0.1738\n",
            "Epoch 471/700\n",
            "15/15 [==============================] - 0s 294us/step - loss: 0.1719\n",
            "Epoch 472/700\n",
            "15/15 [==============================] - 0s 305us/step - loss: 0.1700\n",
            "Epoch 473/700\n",
            "15/15 [==============================] - 0s 328us/step - loss: 0.1682\n",
            "Epoch 474/700\n",
            "15/15 [==============================] - 0s 354us/step - loss: 0.1664\n",
            "Epoch 475/700\n",
            "15/15 [==============================] - 0s 293us/step - loss: 0.1645\n",
            "Epoch 476/700\n",
            "15/15 [==============================] - 0s 312us/step - loss: 0.1628\n",
            "Epoch 477/700\n",
            "15/15 [==============================] - 0s 316us/step - loss: 0.1610\n",
            "Epoch 478/700\n",
            "15/15 [==============================] - 0s 339us/step - loss: 0.1592\n",
            "Epoch 479/700\n",
            "15/15 [==============================] - 0s 295us/step - loss: 0.1575\n",
            "Epoch 480/700\n",
            "15/15 [==============================] - 0s 308us/step - loss: 0.1558\n",
            "Epoch 481/700\n",
            "15/15 [==============================] - 0s 294us/step - loss: 0.1541\n",
            "Epoch 482/700\n",
            "15/15 [==============================] - 0s 332us/step - loss: 0.1524\n",
            "Epoch 483/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 0.1508\n",
            "Epoch 484/700\n",
            "15/15 [==============================] - 0s 302us/step - loss: 0.1491\n",
            "Epoch 485/700\n",
            "15/15 [==============================] - 0s 243us/step - loss: 0.1475\n",
            "Epoch 486/700\n",
            "15/15 [==============================] - 0s 581us/step - loss: 0.1459\n",
            "Epoch 487/700\n",
            "15/15 [==============================] - 0s 272us/step - loss: 0.1443\n",
            "Epoch 488/700\n",
            "15/15 [==============================] - 0s 249us/step - loss: 0.1427\n",
            "Epoch 489/700\n",
            "15/15 [==============================] - 0s 253us/step - loss: 0.1412\n",
            "Epoch 490/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 0.1396\n",
            "Epoch 491/700\n",
            "15/15 [==============================] - 0s 279us/step - loss: 0.1381\n",
            "Epoch 492/700\n",
            "15/15 [==============================] - 0s 675us/step - loss: 0.1366\n",
            "Epoch 493/700\n",
            "15/15 [==============================] - 0s 407us/step - loss: 0.1351\n",
            "Epoch 494/700\n",
            "15/15 [==============================] - 0s 519us/step - loss: 0.1336\n",
            "Epoch 495/700\n",
            "15/15 [==============================] - 0s 328us/step - loss: 0.1322\n",
            "Epoch 496/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 0.1308\n",
            "Epoch 497/700\n",
            "15/15 [==============================] - 0s 314us/step - loss: 0.1293\n",
            "Epoch 498/700\n",
            "15/15 [==============================] - 0s 329us/step - loss: 0.1279\n",
            "Epoch 499/700\n",
            "15/15 [==============================] - 0s 330us/step - loss: 0.1265\n",
            "Epoch 500/700\n",
            "15/15 [==============================] - 0s 264us/step - loss: 0.1252\n",
            "Epoch 501/700\n",
            "15/15 [==============================] - 0s 303us/step - loss: 0.1238\n",
            "Epoch 502/700\n",
            "15/15 [==============================] - 0s 339us/step - loss: 0.1224\n",
            "Epoch 503/700\n",
            "15/15 [==============================] - 0s 257us/step - loss: 0.1211\n",
            "Epoch 504/700\n",
            "15/15 [==============================] - 0s 293us/step - loss: 0.1198\n",
            "Epoch 505/700\n",
            "15/15 [==============================] - 0s 307us/step - loss: 0.1185\n",
            "Epoch 506/700\n",
            "15/15 [==============================] - 0s 256us/step - loss: 0.1172\n",
            "Epoch 507/700\n",
            "15/15 [==============================] - 0s 248us/step - loss: 0.1159\n",
            "Epoch 508/700\n",
            "15/15 [==============================] - 0s 271us/step - loss: 0.1147\n",
            "Epoch 509/700\n",
            "15/15 [==============================] - 0s 266us/step - loss: 0.1134\n",
            "Epoch 510/700\n",
            "15/15 [==============================] - 0s 294us/step - loss: 0.1122\n",
            "Epoch 511/700\n",
            "15/15 [==============================] - 0s 276us/step - loss: 0.1110\n",
            "Epoch 512/700\n",
            "15/15 [==============================] - 0s 270us/step - loss: 0.1097\n",
            "Epoch 513/700\n",
            "15/15 [==============================] - 0s 226us/step - loss: 0.1086\n",
            "Epoch 514/700\n",
            "15/15 [==============================] - 0s 251us/step - loss: 0.1074\n",
            "Epoch 515/700\n",
            "15/15 [==============================] - 0s 252us/step - loss: 0.1062\n",
            "Epoch 516/700\n",
            "15/15 [==============================] - 0s 254us/step - loss: 0.1050\n",
            "Epoch 517/700\n",
            "15/15 [==============================] - 0s 310us/step - loss: 0.1039\n",
            "Epoch 518/700\n",
            "15/15 [==============================] - 0s 313us/step - loss: 0.1028\n",
            "Epoch 519/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 0.1016\n",
            "Epoch 520/700\n",
            "15/15 [==============================] - 0s 314us/step - loss: 0.1005\n",
            "Epoch 521/700\n",
            "15/15 [==============================] - 0s 291us/step - loss: 0.0994\n",
            "Epoch 522/700\n",
            "15/15 [==============================] - 0s 275us/step - loss: 0.0984\n",
            "Epoch 523/700\n",
            "15/15 [==============================] - 0s 266us/step - loss: 0.0973\n",
            "Epoch 524/700\n",
            "15/15 [==============================] - 0s 274us/step - loss: 0.0962\n",
            "Epoch 525/700\n",
            "15/15 [==============================] - 0s 315us/step - loss: 0.0952\n",
            "Epoch 526/700\n",
            "15/15 [==============================] - 0s 287us/step - loss: 0.0942\n",
            "Epoch 527/700\n",
            "15/15 [==============================] - 0s 289us/step - loss: 0.0931\n",
            "Epoch 528/700\n",
            "15/15 [==============================] - 0s 318us/step - loss: 0.0921\n",
            "Epoch 529/700\n",
            "15/15 [==============================] - 0s 327us/step - loss: 0.0911\n",
            "Epoch 530/700\n",
            "15/15 [==============================] - 0s 311us/step - loss: 0.0901\n",
            "Epoch 531/700\n",
            "15/15 [==============================] - 0s 283us/step - loss: 0.0891\n",
            "Epoch 532/700\n",
            "15/15 [==============================] - 0s 290us/step - loss: 0.0882\n",
            "Epoch 533/700\n",
            "15/15 [==============================] - 0s 292us/step - loss: 0.0872\n",
            "Epoch 534/700\n",
            "15/15 [==============================] - 0s 290us/step - loss: 0.0863\n",
            "Epoch 535/700\n",
            "15/15 [==============================] - 0s 255us/step - loss: 0.0853\n",
            "Epoch 536/700\n",
            "15/15 [==============================] - 0s 252us/step - loss: 0.0844\n",
            "Epoch 537/700\n",
            "15/15 [==============================] - 0s 302us/step - loss: 0.0835\n",
            "Epoch 538/700\n",
            "15/15 [==============================] - 0s 217us/step - loss: 0.0826\n",
            "Epoch 539/700\n",
            "15/15 [==============================] - 0s 314us/step - loss: 0.0817\n",
            "Epoch 540/700\n",
            "15/15 [==============================] - 0s 200us/step - loss: 0.0808\n",
            "Epoch 541/700\n",
            "15/15 [==============================] - 0s 294us/step - loss: 0.0799\n",
            "Epoch 542/700\n",
            "15/15 [==============================] - 0s 247us/step - loss: 0.0790\n",
            "Epoch 543/700\n",
            "15/15 [==============================] - 0s 240us/step - loss: 0.0782\n",
            "Epoch 544/700\n",
            "15/15 [==============================] - 0s 274us/step - loss: 0.0773\n",
            "Epoch 545/700\n",
            "15/15 [==============================] - 0s 293us/step - loss: 0.0765\n",
            "Epoch 546/700\n",
            "15/15 [==============================] - 0s 315us/step - loss: 0.0756\n",
            "Epoch 547/700\n",
            "15/15 [==============================] - 0s 273us/step - loss: 0.0748\n",
            "Epoch 548/700\n",
            "15/15 [==============================] - 0s 249us/step - loss: 0.0740\n",
            "Epoch 549/700\n",
            "15/15 [==============================] - 0s 227us/step - loss: 0.0732\n",
            "Epoch 550/700\n",
            "15/15 [==============================] - 0s 200us/step - loss: 0.0724\n",
            "Epoch 551/700\n",
            "15/15 [==============================] - 0s 247us/step - loss: 0.0716\n",
            "Epoch 552/700\n",
            "15/15 [==============================] - 0s 224us/step - loss: 0.0708\n",
            "Epoch 553/700\n",
            "15/15 [==============================] - 0s 220us/step - loss: 0.0701\n",
            "Epoch 554/700\n",
            "15/15 [==============================] - 0s 352us/step - loss: 0.0693\n",
            "Epoch 555/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 0.0685\n",
            "Epoch 556/700\n",
            "15/15 [==============================] - 0s 312us/step - loss: 0.0678\n",
            "Epoch 557/700\n",
            "15/15 [==============================] - 0s 420us/step - loss: 0.0671\n",
            "Epoch 558/700\n",
            "15/15 [==============================] - 0s 627us/step - loss: 0.0663\n",
            "Epoch 559/700\n",
            "15/15 [==============================] - 0s 577us/step - loss: 0.0656\n",
            "Epoch 560/700\n",
            "15/15 [==============================] - 0s 536us/step - loss: 0.0649\n",
            "Epoch 561/700\n",
            "15/15 [==============================] - 0s 368us/step - loss: 0.0642\n",
            "Epoch 562/700\n",
            "15/15 [==============================] - 0s 323us/step - loss: 0.0635\n",
            "Epoch 563/700\n",
            "15/15 [==============================] - 0s 302us/step - loss: 0.0628\n",
            "Epoch 564/700\n",
            "15/15 [==============================] - 0s 308us/step - loss: 0.0621\n",
            "Epoch 565/700\n",
            "15/15 [==============================] - 0s 295us/step - loss: 0.0614\n",
            "Epoch 566/700\n",
            "15/15 [==============================] - 0s 278us/step - loss: 0.0608\n",
            "Epoch 567/700\n",
            "15/15 [==============================] - 0s 306us/step - loss: 0.0601\n",
            "Epoch 568/700\n",
            "15/15 [==============================] - 0s 275us/step - loss: 0.0594\n",
            "Epoch 569/700\n",
            "15/15 [==============================] - 0s 306us/step - loss: 0.0588\n",
            "Epoch 570/700\n",
            "15/15 [==============================] - 0s 301us/step - loss: 0.0582\n",
            "Epoch 571/700\n",
            "15/15 [==============================] - 0s 377us/step - loss: 0.0575\n",
            "Epoch 572/700\n",
            "15/15 [==============================] - 0s 358us/step - loss: 0.0569\n",
            "Epoch 573/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 0.0563\n",
            "Epoch 574/700\n",
            "15/15 [==============================] - 0s 307us/step - loss: 0.0557\n",
            "Epoch 575/700\n",
            "15/15 [==============================] - 0s 331us/step - loss: 0.0551\n",
            "Epoch 576/700\n",
            "15/15 [==============================] - 0s 332us/step - loss: 0.0545\n",
            "Epoch 577/700\n",
            "15/15 [==============================] - 0s 423us/step - loss: 0.0539\n",
            "Epoch 578/700\n",
            "15/15 [==============================] - 0s 256us/step - loss: 0.0533\n",
            "Epoch 579/700\n",
            "15/15 [==============================] - 0s 233us/step - loss: 0.0527\n",
            "Epoch 580/700\n",
            "15/15 [==============================] - 0s 402us/step - loss: 0.0521\n",
            "Epoch 581/700\n",
            "15/15 [==============================] - 0s 452us/step - loss: 0.0516\n",
            "Epoch 582/700\n",
            "15/15 [==============================] - 0s 461us/step - loss: 0.0510\n",
            "Epoch 583/700\n",
            "15/15 [==============================] - 0s 492us/step - loss: 0.0504\n",
            "Epoch 584/700\n",
            "15/15 [==============================] - 0s 251us/step - loss: 0.0499\n",
            "Epoch 585/700\n",
            "15/15 [==============================] - 0s 335us/step - loss: 0.0494\n",
            "Epoch 586/700\n",
            "15/15 [==============================] - 0s 331us/step - loss: 0.0488\n",
            "Epoch 587/700\n",
            "15/15 [==============================] - 0s 251us/step - loss: 0.0483\n",
            "Epoch 588/700\n",
            "15/15 [==============================] - 0s 225us/step - loss: 0.0478\n",
            "Epoch 589/700\n",
            "15/15 [==============================] - 0s 248us/step - loss: 0.0472\n",
            "Epoch 590/700\n",
            "15/15 [==============================] - 0s 286us/step - loss: 0.0467\n",
            "Epoch 591/700\n",
            "15/15 [==============================] - 0s 228us/step - loss: 0.0462\n",
            "Epoch 592/700\n",
            "15/15 [==============================] - 0s 324us/step - loss: 0.0457\n",
            "Epoch 593/700\n",
            "15/15 [==============================] - 0s 323us/step - loss: 0.0452\n",
            "Epoch 594/700\n",
            "15/15 [==============================] - 0s 250us/step - loss: 0.0447\n",
            "Epoch 595/700\n",
            "15/15 [==============================] - 0s 330us/step - loss: 0.0442\n",
            "Epoch 596/700\n",
            "15/15 [==============================] - 0s 293us/step - loss: 0.0438\n",
            "Epoch 597/700\n",
            "15/15 [==============================] - 0s 279us/step - loss: 0.0433\n",
            "Epoch 598/700\n",
            "15/15 [==============================] - 0s 206us/step - loss: 0.0428\n",
            "Epoch 599/700\n",
            "15/15 [==============================] - 0s 291us/step - loss: 0.0423\n",
            "Epoch 600/700\n",
            "15/15 [==============================] - 0s 274us/step - loss: 0.0419\n",
            "Epoch 601/700\n",
            "15/15 [==============================] - 0s 357us/step - loss: 0.0414\n",
            "Epoch 602/700\n",
            "15/15 [==============================] - 0s 309us/step - loss: 0.0410\n",
            "Epoch 603/700\n",
            "15/15 [==============================] - 0s 303us/step - loss: 0.0405\n",
            "Epoch 604/700\n",
            "15/15 [==============================] - 0s 248us/step - loss: 0.0401\n",
            "Epoch 605/700\n",
            "15/15 [==============================] - 0s 443us/step - loss: 0.0396\n",
            "Epoch 606/700\n",
            "15/15 [==============================] - 0s 367us/step - loss: 0.0392\n",
            "Epoch 607/700\n",
            "15/15 [==============================] - 0s 373us/step - loss: 0.0388\n",
            "Epoch 608/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 0.0384\n",
            "Epoch 609/700\n",
            "15/15 [==============================] - 0s 282us/step - loss: 0.0380\n",
            "Epoch 610/700\n",
            "15/15 [==============================] - 0s 312us/step - loss: 0.0375\n",
            "Epoch 611/700\n",
            "15/15 [==============================] - 0s 334us/step - loss: 0.0371\n",
            "Epoch 612/700\n",
            "15/15 [==============================] - 0s 306us/step - loss: 0.0367\n",
            "Epoch 613/700\n",
            "15/15 [==============================] - 0s 306us/step - loss: 0.0363\n",
            "Epoch 614/700\n",
            "15/15 [==============================] - 0s 262us/step - loss: 0.0359\n",
            "Epoch 615/700\n",
            "15/15 [==============================] - 0s 273us/step - loss: 0.0355\n",
            "Epoch 616/700\n",
            "15/15 [==============================] - 0s 374us/step - loss: 0.0352\n",
            "Epoch 617/700\n",
            "15/15 [==============================] - 0s 301us/step - loss: 0.0348\n",
            "Epoch 618/700\n",
            "15/15 [==============================] - 0s 276us/step - loss: 0.0344\n",
            "Epoch 619/700\n",
            "15/15 [==============================] - 0s 310us/step - loss: 0.0340\n",
            "Epoch 620/700\n",
            "15/15 [==============================] - 0s 320us/step - loss: 0.0336\n",
            "Epoch 621/700\n",
            "15/15 [==============================] - 0s 308us/step - loss: 0.0333\n",
            "Epoch 622/700\n",
            "15/15 [==============================] - 0s 308us/step - loss: 0.0329\n",
            "Epoch 623/700\n",
            "15/15 [==============================] - 0s 392us/step - loss: 0.0326\n",
            "Epoch 624/700\n",
            "15/15 [==============================] - 0s 278us/step - loss: 0.0322\n",
            "Epoch 625/700\n",
            "15/15 [==============================] - 0s 351us/step - loss: 0.0319\n",
            "Epoch 626/700\n",
            "15/15 [==============================] - 0s 317us/step - loss: 0.0315\n",
            "Epoch 627/700\n",
            "15/15 [==============================] - 0s 322us/step - loss: 0.0312\n",
            "Epoch 628/700\n",
            "15/15 [==============================] - 0s 357us/step - loss: 0.0308\n",
            "Epoch 629/700\n",
            "15/15 [==============================] - 0s 329us/step - loss: 0.0305\n",
            "Epoch 630/700\n",
            "15/15 [==============================] - 0s 298us/step - loss: 0.0302\n",
            "Epoch 631/700\n",
            "15/15 [==============================] - 0s 278us/step - loss: 0.0298\n",
            "Epoch 632/700\n",
            "15/15 [==============================] - 0s 218us/step - loss: 0.0295\n",
            "Epoch 633/700\n",
            "15/15 [==============================] - 0s 229us/step - loss: 0.0292\n",
            "Epoch 634/700\n",
            "15/15 [==============================] - 0s 312us/step - loss: 0.0289\n",
            "Epoch 635/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 0.0286\n",
            "Epoch 636/700\n",
            "15/15 [==============================] - 0s 196us/step - loss: 0.0282\n",
            "Epoch 637/700\n",
            "15/15 [==============================] - 0s 197us/step - loss: 0.0279\n",
            "Epoch 638/700\n",
            "15/15 [==============================] - 0s 242us/step - loss: 0.0276\n",
            "Epoch 639/700\n",
            "15/15 [==============================] - 0s 247us/step - loss: 0.0273\n",
            "Epoch 640/700\n",
            "15/15 [==============================] - 0s 329us/step - loss: 0.0270\n",
            "Epoch 641/700\n",
            "15/15 [==============================] - 0s 424us/step - loss: 0.0267\n",
            "Epoch 642/700\n",
            "15/15 [==============================] - 0s 398us/step - loss: 0.0264\n",
            "Epoch 643/700\n",
            "15/15 [==============================] - 0s 485us/step - loss: 0.0262\n",
            "Epoch 644/700\n",
            "15/15 [==============================] - 0s 256us/step - loss: 0.0259\n",
            "Epoch 645/700\n",
            "15/15 [==============================] - 0s 252us/step - loss: 0.0256\n",
            "Epoch 646/700\n",
            "15/15 [==============================] - 0s 306us/step - loss: 0.0253\n",
            "Epoch 647/700\n",
            "15/15 [==============================] - 0s 256us/step - loss: 0.0250\n",
            "Epoch 648/700\n",
            "15/15 [==============================] - 0s 260us/step - loss: 0.0248\n",
            "Epoch 649/700\n",
            "15/15 [==============================] - 0s 227us/step - loss: 0.0245\n",
            "Epoch 650/700\n",
            "15/15 [==============================] - 0s 261us/step - loss: 0.0242\n",
            "Epoch 651/700\n",
            "15/15 [==============================] - 0s 284us/step - loss: 0.0240\n",
            "Epoch 652/700\n",
            "15/15 [==============================] - 0s 236us/step - loss: 0.0237\n",
            "Epoch 653/700\n",
            "15/15 [==============================] - 0s 269us/step - loss: 0.0234\n",
            "Epoch 654/700\n",
            "15/15 [==============================] - 0s 292us/step - loss: 0.0232\n",
            "Epoch 655/700\n",
            "15/15 [==============================] - 0s 296us/step - loss: 0.0229\n",
            "Epoch 656/700\n",
            "15/15 [==============================] - 0s 455us/step - loss: 0.0227\n",
            "Epoch 657/700\n",
            "15/15 [==============================] - 0s 420us/step - loss: 0.0224\n",
            "Epoch 658/700\n",
            "15/15 [==============================] - 0s 417us/step - loss: 0.0222\n",
            "Epoch 659/700\n",
            "15/15 [==============================] - 0s 365us/step - loss: 0.0220\n",
            "Epoch 660/700\n",
            "15/15 [==============================] - 0s 452us/step - loss: 0.0217\n",
            "Epoch 661/700\n",
            "15/15 [==============================] - 0s 423us/step - loss: 0.0215\n",
            "Epoch 662/700\n",
            "15/15 [==============================] - 0s 359us/step - loss: 0.0212\n",
            "Epoch 663/700\n",
            "15/15 [==============================] - 0s 341us/step - loss: 0.0210\n",
            "Epoch 664/700\n",
            "15/15 [==============================] - 0s 350us/step - loss: 0.0208\n",
            "Epoch 665/700\n",
            "15/15 [==============================] - 0s 411us/step - loss: 0.0206\n",
            "Epoch 666/700\n",
            "15/15 [==============================] - 0s 430us/step - loss: 0.0203\n",
            "Epoch 667/700\n",
            "15/15 [==============================] - 0s 371us/step - loss: 0.0201\n",
            "Epoch 668/700\n",
            "15/15 [==============================] - 0s 359us/step - loss: 0.0199\n",
            "Epoch 669/700\n",
            "15/15 [==============================] - 0s 270us/step - loss: 0.0197\n",
            "Epoch 670/700\n",
            "15/15 [==============================] - 0s 225us/step - loss: 0.0195\n",
            "Epoch 671/700\n",
            "15/15 [==============================] - 0s 236us/step - loss: 0.0193\n",
            "Epoch 672/700\n",
            "15/15 [==============================] - 0s 215us/step - loss: 0.0190\n",
            "Epoch 673/700\n",
            "15/15 [==============================] - 0s 252us/step - loss: 0.0188\n",
            "Epoch 674/700\n",
            "15/15 [==============================] - 0s 212us/step - loss: 0.0186\n",
            "Epoch 675/700\n",
            "15/15 [==============================] - 0s 216us/step - loss: 0.0184\n",
            "Epoch 676/700\n",
            "15/15 [==============================] - 0s 214us/step - loss: 0.0182\n",
            "Epoch 677/700\n",
            "15/15 [==============================] - 0s 215us/step - loss: 0.0180\n",
            "Epoch 678/700\n",
            "15/15 [==============================] - 0s 277us/step - loss: 0.0178\n",
            "Epoch 679/700\n",
            "15/15 [==============================] - 0s 321us/step - loss: 0.0176\n",
            "Epoch 680/700\n",
            "15/15 [==============================] - 0s 303us/step - loss: 0.0174\n",
            "Epoch 681/700\n",
            "15/15 [==============================] - 0s 252us/step - loss: 0.0173\n",
            "Epoch 682/700\n",
            "15/15 [==============================] - 0s 206us/step - loss: 0.0171\n",
            "Epoch 683/700\n",
            "15/15 [==============================] - 0s 240us/step - loss: 0.0169\n",
            "Epoch 684/700\n",
            "15/15 [==============================] - 0s 305us/step - loss: 0.0167\n",
            "Epoch 685/700\n",
            "15/15 [==============================] - 0s 207us/step - loss: 0.0165\n",
            "Epoch 686/700\n",
            "15/15 [==============================] - 0s 266us/step - loss: 0.0163\n",
            "Epoch 687/700\n",
            "15/15 [==============================] - 0s 253us/step - loss: 0.0162\n",
            "Epoch 688/700\n",
            "15/15 [==============================] - 0s 337us/step - loss: 0.0160\n",
            "Epoch 689/700\n",
            "15/15 [==============================] - 0s 378us/step - loss: 0.0158\n",
            "Epoch 690/700\n",
            "15/15 [==============================] - 0s 377us/step - loss: 0.0156\n",
            "Epoch 691/700\n",
            "15/15 [==============================] - 0s 371us/step - loss: 0.0155\n",
            "Epoch 692/700\n",
            "15/15 [==============================] - 0s 376us/step - loss: 0.0153\n",
            "Epoch 693/700\n",
            "15/15 [==============================] - 0s 379us/step - loss: 0.0151\n",
            "Epoch 694/700\n",
            "15/15 [==============================] - 0s 348us/step - loss: 0.0150\n",
            "Epoch 695/700\n",
            "15/15 [==============================] - 0s 349us/step - loss: 0.0148\n",
            "Epoch 696/700\n",
            "15/15 [==============================] - 0s 299us/step - loss: 0.0146\n",
            "Epoch 697/700\n",
            "15/15 [==============================] - 0s 233us/step - loss: 0.0145\n",
            "Epoch 698/700\n",
            "15/15 [==============================] - 0s 426us/step - loss: 0.0143\n",
            "Epoch 699/700\n",
            "15/15 [==============================] - 0s 319us/step - loss: 0.0142\n",
            "Epoch 700/700\n",
            "15/15 [==============================] - 0s 271us/step - loss: 0.0140\n",
            "[-35 -38 -41 -44 -47]\n",
            "[[-34.874916]\n",
            " [-37.85163 ]\n",
            " [-40.828346]\n",
            " [-43.805065]\n",
            " [-46.78178 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qQcNLTQcJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdrP_vI3QcNd",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2At3z2IdQew-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "matplolib inline 명령어를 통해서\n",
        "matplot으로 그리는 플롯들을 주피터 노트북 내에서 볼 수 있게 해준다.\n",
        "포맷을 retina로 바꾸면 그래프의 화질이 훨씬 좋아진다.\n",
        "'''\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "'''\n",
        "라이브러리들을 불러오자.\n",
        "'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "import random as rd\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7A8vUrQRpPd",
        "colab_type": "text"
      },
      "source": [
        "### Data Loading & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBQdcFgkRiv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GKNGA5qRnf-",
        "colab_type": "code",
        "outputId": "f2e22f51-3f3c-4f15-e10d-e42a1cabebd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW4ZeZcNRouf",
        "colab_type": "code",
        "outputId": "3f0d0197-fb2a-421c-bb16-8ecbbbc902fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "'''\n",
        "Ctrl+Enter를 이용하여\n",
        "반복 실행 해보자!\n",
        "'''\n",
        "\n",
        "id = rd.randrange(0,10000)\n",
        "\n",
        "print('id = {}'.format(id))\n",
        "print('다음 그림은 숫자 {} 입니다.'.format(test_y[id]))\n",
        "plt.imshow(test_x[id])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id = 1948\n",
            "다음 그림은 숫자 5 입니다.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHLZJREFUeJzt3XuwZVV9J/DvD1AIPTyUURk1BjE8\nUhohYAKBBHkkBnRUiJAxMyFMBlLGPAxGJ0kZjKjJlJWkfEQTTUVHpmAyhMHSjAk+hpdgMDq2UUJ8\nIEKLzqAI2DwV7GbNH2e3adp7+3HO6bvvXffzqTq179l7r7N+vXt3f+86Z5+1q7UWAKBPu4xdAACw\n8wh6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6\nAOiYoAeAjgl6AOjYbmMXsDNU1S1J9k6ybuRSAGBaByS5p7X21FlepMugT7L3Ltn1sWuy12PHLgQA\npnF/7s3D2Tjz64wa9FX15CSvS3Jykv2S3JbkfUle21r75gwvvW5N9nrsUfVTc6gSAJbex9vluTfr\n1836OqMFfVU9Lcl1SR6f5G+SfD7JjyX5zSQnV9WxrbU7x6oPAHow5sV4f55JyL+stXZqa+13W2sn\nJnlTkkOS/OGItQFAF0YJ+mE0/5xMLpb7sy02vybJ/UnOrKo1S1waAHRlrBH9CcPyw621hzff0Fq7\nN8nfJ9kzydFLXRgA9GSsz+gPGZY3LrL9i5mM+A9OcsViL1JVaxfZdOj0pQFAP8Ya0e8zLO9eZPum\n9fsuQS0A0K0V/T361tqRC60fRvpHLHE5ALDsjDWi3zRi32eR7ZvWr1+CWgCgW2MF/ReG5cGLbD9o\nWC72GT4AsB3GCvqrhuVzquoRNVTVXkmOTfJAkn9Y6sIAoCejBH1r7UtJPpzJhP2/tsXm1yZZk+TC\n1tr9S1waAHRlzIvxfjWTKXD/tKpOSvK5JEdl8h37G5P83oi1AUAXRpsCdxjVPyvJBZkE/CuSPC3J\nW5IcbZ57AJjdqF+va619JckvjVkDAPRszJvaAAA7maAHgI4JegDomKAHgI4JegDomKAHgI4JegDo\nmKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAH\ngI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4J\negDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDo\nmKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAH\ngI4JegDomKAHgI4JegDomKAHgI4JegDo2GhBX1Xrqqot8vjaWHUBQE92G7n/u5O8eYH19y11IQDQ\no7GDfn1r7fyRawCAbvmMHgA6NvaIfveq+oUkT0lyf5Lrk1zTWts4blkA0Iexg37/JBduse6Wqvql\n1tpHttW4qtYusunQmSsDgA6M+db9u5OclEnYr0nyw0n+IskBST5QVYeNVxoA9GG0EX1r7bVbrLoh\nya9U1X1JXpHk/CSnbeM1jlxo/TDSP2IOZQLAirYcL8Z7x7A8btQqAKADyzHovzEs14xaBQB0YDkG\n/dHD8uZRqwCADowS9FX1Q1X1PSP2qjogyduGpxctZU0A0KOxLsb7d0leUVXXJPlyknuTPC3J85Ls\nkeSyJH8yUm0A0I2xgv6qJIck+ZEkx2byefz6JB/N5Hv1F7bW2ki1AUA3Rgn6YTKcbU6IAwDMZjle\njAcAzImgB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA\n6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6Jig\nB4COCXoA6JigB4COCXoA6JigB4CO7TZ2AQBLbZc995yt/d57Td32688/cKa+H9y3pm77uM88NFPf\n33f9V6Zu2x6cre+N69dP37i1mfpe6YzoAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4A\nOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBj7kcPTGWXvaa/J3uS3HHGM2Zq//Bpd07d\n9jcOunqmvv/j3rfP1H41+sSD35mp/UuuP3Pqto9/4edn6nulM6IHgI4JegDomKAHgI4JegDomKAH\ngI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomNvUsmzs+q/3m7pte+Lj\nZur7qz/z2Knb3v+UjTP1vctDNXXbXb81fdskeejxG6Zue95Pvn+mvs/e59qZ2l9y3z5Tt33dDf92\npr5fe8eeU7fd/+pdZ+p7929Of77dcdijZur7oX3a1G2feM3051qSTP+3zVxG9FV1elW9taqurap7\nqqpV1UXbaHNMVV1WVXdV1beq6vqqOreqZvtXAAB817xG9OclOSzJfUm+muTQre1cVS9M8p4k307y\n10nuSvL8JG9KcmySM+ZUFwCsavP6jP7lSQ5OsneSl25tx6raO8lfJtmY5PjW2tmttf+c5PAkH0ty\nelW9eE51AcCqNpegb61d1Vr7Ymttez7AOT3J45Jc3Fr75Gav8e1M3hlItvHLAgCwfca46v7EYfnB\nBbZdk+SBJMdU1e5LVxIA9GmMoD9kWN645YbW2oYkt2Ry7cCBS1kUAPRojK/XbfqWxN2LbN+0ft9t\nvVBVrV1k01YvBgSA1cKEOQDQsTFG9JtG7IvNf7Bp/fptvVBr7ciF1g8j/SN2vDQA6MsYI/ovDMuD\nt9xQVbsleWqSDUluXsqiAKBHYwT9lcPy5AW2HZdkzyTXtdYeXLqSAKBPYwT9pUnuSPLiqnrWppVV\ntUeSPxievn2EugCgO3P5jL6qTk1y6vB0/2H541V1wfDzHa21VyZJa+2eqvrlTAL/6qq6OJMpcF+Q\nyVfvLs1kWlwAYEbzuhjv8CRnbbHuwPzLd+G/nOSVmza01t5XVc9O8ntJXpRkjyQ3JfmtJH+6nTPs\nAQDbMJegb62dn+T8HWzz90meO4/+AYCFuR89j7TL9HcJvvvnf3Smrk/57Wumbvuax10xU9+r1a0b\n7pu67XM/+ZKZ+v7L9+w1U/t9/vs/TN32SfnnmfpeqZ70gbErYAwmzAGAjgl6AOiYoAeAjgl6AOiY\noAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiY29TyCDf++ZFTt73l\nBe+Yqe833nXg1G0PuuilM/V91E98bvq+19w+U9//80s/MnXbB2/ae6a+f/Cib07d9knXr85bvcJK\nY0QPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEP\nAB0T9ADQMUEPAB1zP3oe4Td+4vLR+n73F4+euu1B/+2umfr+xm+vn75tHj1T30/KePd1f3i0noGl\nYkQPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEP\nAB0T9ADQMbep5RGueN7Tp277uUv+zUx9/9NRfzV129s+cN9MfT/3H8+Zuu2aC/eZqe81l358pvYA\nW2NEDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFB\nDwAdE/QA0DFBDwAdcz96HmHDl78yddtbf3zXmfp+3g+8cOq2n/3tJ8zU9+XPfePUbZ/8rN1n6vu9\nf/j4qdu+7qKfn6nvAy65feq2G79w00x9A0tjLiP6qjq9qt5aVddW1T1V1arqokX2PWDYvtjj4nnU\nBADMb0R/XpLDktyX5KtJDt2ONp9J8r4F1t8wp5oAYNWbV9C/PJOAvynJs5NctR1tPt1aO39O/QMA\nC5hL0LfWvhvsVTWPlwQA5mDMi/GeWFUvSbJfkjuTfKy1dv2I9QBAd8YM+p8eHt9VVVcnOau1duv2\nvEBVrV1k0/ZcIwAA3Rvje/QPJHl9kiOTPGZ4bPpc//gkV1TVmhHqAoDuLPmIvrV2e5Lf32L1NVX1\nnCQfTXJUknOSvGU7XuvIhdYPI/0jZiwVAFa8ZTMzXmttQ5J3Dk+PG7MWAOjFsgn6wTeGpbfuAWAO\nllvQHz0sbx61CgDoxJIHfVUdUVXf029VnZTJxDtJsuD0uQDAjpnLxXhVdWqSU4en+w/LH6+qC4af\n72itvXL4+Y1JDqqq6zKZTS9JnpnkxOHnV7fWrptHXQCw2s3rqvvDk5y1xboDh0eSfDnJpqC/MMlp\nSX40ySlJHpXk60kuSfK21tq1c6oJAFa9eU2Be36S87dz33cledc8+gUAtq5aa2PXMHdVtXav7HvE\nUfVTY5fCCrHLnntO3fa2cw6fqe8f+ff/NHXbdz9ltjfAHnj4oanbPv0DvzZT3z/0R3fO1H7jF12z\nS98+3i7PvVn/qcXmjNley+2qewBgjgQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANA\nxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHTMbWphBdvtB75/pva3/ML07X/3zEtm6nv/3e6eqf1Lrj5r\n6rYHXFoz9f3oD/6fmdrD9nCbWgBgmwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANA\nxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAx9yPHhjFV191zEztL/+VP5q67R412xjnyP/18qnb\nHnzuP87Ud/vOQzO1Z+VwP3oAYJsEPQB0TNADQMcEPQB0TNADQMcEPQB0TNADQMcEPQB0TNADQMcE\nPQB0TNADQMcEPQB0TNADQMcEPQB0bLexCwBWpyf/l+tman/2JWdO3fYrf/x9M/V9/QvfMnXbw/Z+\n6Ux9H/Sf/nnqtm5xuzoZ0QNAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9\nAHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAx9yPHliRNt50y9Rtn3jabH0f/scvn7rtl/7D22fq+5DX\nTH8/+wPO+9hMfbMyzTyir6r9quqcqnpvVd1UVd+qqrur6qNVdXZVLdhHVR1TVZdV1V1Dm+ur6tyq\n2nXWmgCAiXmM6M9I8vYktyW5KsmtSZ6Q5GeTvDPJKVV1RmutbWpQVS9M8p4k307y10nuSvL8JG9K\ncuzwmgDAjOYR9DcmeUGSv2utPbxpZVW9Ksknkrwok9B/z7B+7yR/mWRjkuNba58c1r86yZVJTq+q\nF7fWLp5DbQCwqs381n1r7crW2vs3D/lh/deSvGN4evxmm05P8rgkF28K+WH/byc5b3g6/YdQAMB3\n7eyr7r8zLDdstu7EYfnBBfa/JskDSY6pqt13ZmEAsBrstKvuq2q3JL84PN081A8Zljdu2aa1tqGq\nbkny9CQHJvncNvpYu8imQ3esWgDo084c0b8hyTOSXNZa+9Bm6/cZlncv0m7T+n13VmEAsFrslBF9\nVb0sySuSfD7JmTujjyRprR25SP9rkxyxs/oFgJVi7iP6qvr1JG9J8tkkJ7TW7tpil00j9n2ysE3r\n18+7NgBYbeYa9FV1bpK3Jrkhk5D/2gK7fWFYHrxA+92SPDWTi/dunmdtALAazS3oq+p3Mpnw5tOZ\nhPzti+x65bA8eYFtxyXZM8l1rbUH51UbAKxWcwn6YbKbNyRZm+Sk1todW9n90iR3JHlxVT1rs9fY\nI8kfDE9nmwwaAEgyh4vxquqsJK/LZKa7a5O8rKq23G1da+2CJGmt3VNVv5xJ4F9dVRdnMgXuCzL5\n6t2lmUyLCwDMaB5X3T91WO6a5NxF9vlIkgs2PWmtva+qnp3k9zKZInePJDcl+a0kf7r5vPgAwPSq\nx0ytqrV7Zd8jjqqfGrsUoEO77Lnn1G1PW7tupr5ve2j6KUauO+zRM/XN0vp4uzz3Zv2nFvsq+fba\n2VPgAgAjEvQA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFB\nDwAdE/QA0DFBDwAd223sAgBWms+/+elTtz3jX10+U9/H/8krp267f66bqW9WJiN6AOiYoAeAjgl6\nAOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjrlNLTCK\n+37u6JnaP7hXTd92v+nbJsmnTvmTqdv+1b2HzNT3ky9dN3XbDTP1zEplRA8AHRP0ANAxQQ8AHRP0\nANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHXM/emAU\nG3af7Z7w7zzvzVO3PXz33Wfq+7zbj5q67Sd+9YiZ+q7/+5mZ2rP6GNEDQMcEPQB0TNADQMcEPQB0\nTNADQMcEPQB0TNADQMcEPQB0TNADQMcEPQB0TNADQMcEPQB0TNADQMcEPQB0zG1qgVHse+HHZmr/\nqr89efrGj37UTH0/fNf6qdvWd9xmlqU184i+qvarqnOq6r1VdVNVfauq7q6qj1bV2VW1yxb7H1BV\nbSuPi2etCQCYmMeI/owkb09yW5Krktya5AlJfjbJO5OcUlVntNbaFu0+k+R9C7zeDXOoCQDIfIL+\nxiQvSPJ3rbWHN62sqlcl+USSF2US+u/Zot2nW2vnz6F/AGARM79131q7srX2/s1Dflj/tSTvGJ4e\nP2s/AMCO29kX431nWG5YYNsTq+olSfZLcmeSj7XWrt/J9QDAqrLTgr6qdkvyi8PTDy6wy08Pj83b\nXJ3krNbarTurLgBYTXbmiP4NSZ6R5LLW2oc2W/9AktdnciHezcO6ZyY5P8kJSa6oqsNba/dvq4Oq\nWrvIpkOnLRoAerJTJsypqpcleUWSzyc5c/NtrbXbW2u/31r7VGtt/fC4Jslzknw8yQ8mOWdn1AUA\nq83cR/RV9etJ3pLks0lOaq3dtT3tWmsbquqdSY5KctzwGttqc+QiNaxNcsR2Fw0AnZrriL6qzk3y\n1ky+C3/CcOX9jvjGsFwzz7oAYLWaW9BX1e8keVOST2cS8rdP8TJHD8ubt7oXALBd5hL0VfXqTC6+\nW5vJ2/V3bGXfI7acFndYf1KSlw9PL5pHXQCw2s38GX1VnZXkdUk2Jrk2ycuqasvd1rXWLhh+fmOS\ng6rquiRfHdY9M8mJw8+vbq1dN2tdAMB8LsZ76rDcNcm5i+zzkSQXDD9fmOS0JD+a5JQkj0ry9SSX\nJHlba+3aOdQEAGQOQT/MV3/+Duz/riTvmrVfAGDb3I8eWJE2fvObY5cAK8JOmTAHAFgeBD0AdEzQ\nA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DH\nBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0A\ndEzQA0DHqrU2dg1zV1V37pJdH7sme41dCgBM5f7cm4ez8a7W2n6zvM5u8ypombnn4WzMvVm/bpHt\nhw7Lzy9RPT1wzKbjuE3Hcdtxjtl0lvNxOyDJPbO+SJcj+m2pqrVJ0lo7cuxaVgrHbDqO23Qctx3n\nmE1nNRw3n9EDQMcEPQB0TNADQMcEPQB0TNADQMdW5VX3ALBaGNEDQMcEPQB0TNADQMcEPQB0TNAD\nQMcEPQB0TNADQMdWVdBX1ZOr6r9W1f+rqgeral1VvbmqHjN2bcvVcIzaIo+vjV3fWKrq9Kp6a1Vd\nW1X3DMfjom20OaaqLququ6rqW1V1fVWdW1W7LlXdY9uR41ZVB2zl3GtVdfFS1z+Gqtqvqs6pqvdW\n1U3DuXN3VX20qs6uqgX/H1/t59uOHreez7de70f/ParqaUmuS/L4JH+Tyb2HfyzJbyY5uaqOba3d\nOWKJy9ndSd68wPr7lrqQZeS8JIdlcgy+mn+5p/WCquqFSd6T5NtJ/jrJXUmen+RNSY5NcsbOLHYZ\n2aHjNvhMkvctsP6GOda1nJ2R5O1JbktyVZJbkzwhyc8meWeSU6rqjLbZ7GfOtyRTHLdBf+dba21V\nPJJ8KElL8htbrH/jsP4dY9e4HB9J1iVZN3Ydy+2R5IQkByWpJMcP59BFi+y7d5LbkzyY5Fmbrd8j\nk18+W5IXj/1nWobH7YBh+wVj1z3yMTsxk5DeZYv1+2cSXi3JizZb73yb7rh1e76tirfuh9H8czIJ\nrT/bYvNrktyf5MyqWrPEpbFCtdauaq19sQ3/Q2zD6Ukel+Ti1tonN3uNb2cywk2Sl+6EMpedHTxu\nJGmtXdlae39r7eEt1n8tyTuGp8dvtsn5lqmOW7dWy1v3JwzLDy/wl35vVf19Jr8IHJ3kiqUubgXY\nvap+IclTMvml6Pok17TWNo5b1opx4rD84ALbrknyQJJjqmr31tqDS1fWivHEqnpJkv2S3JnkY621\n60euabn4zrDcsNk659u2LXTcNunufFstQX/IsLxxke1fzCToD46gX8j+SS7cYt0tVfVLrbWPjFHQ\nCrPo+dda21BVtyR5epIDk3xuKQtbIX56eHxXVV2d5KzW2q2jVLQMVNVuSX5xeLp5qDvftmIrx22T\n7s63VfHWfZJ9huXdi2zftH7fJahlpXl3kpMyCfs1SX44yV9k8nnWB6rqsPFKWzGcf9N5IMnrkxyZ\n5DHD49mZXFh1fJIrVvnHbW9I8owkl7XWPrTZeufb1i123Lo931ZL0DOl1tprh8+6vt5ae6C1dkNr\n7VcyuYjx+5KcP26F9Kq1dntr7fdba59qra0fHtdk8u7bx5P8YJJzxq1yHFX1siSvyOTbQ2eOXM6K\nsbXj1vP5tlqCftNvsPsssn3T+vVLUEsvNl3MctyoVawMzr85aq1tyOTrUckqPP+q6teTvCXJZ5Oc\n0Fq7a4tdnG8L2I7jtqAezrfVEvRfGJYHL7L9oGG52Gf4fK9vDMsV+VbWElv0/Bs+L3xqJhcF3byU\nRa1wq/L8q6pzk7w1k+90nzBcQb4l59sWtvO4bc2KPt9WS9BfNSyfs8BsSHtlMoHEA0n+YakLW8GO\nHpar5j+LGVw5LE9eYNtxSfZMct0qvgJ6Gqvu/Kuq38lkwptPZxJWty+yq/NtMztw3LZmRZ9vqyLo\nW2tfSvLhTC4g+7UtNr82k9/SLmyt3b/EpS1rVfVDC118UlUHJHnb8HSr076SJLk0yR1JXlxVz9q0\nsqr2SPIHw9O3j1HYclZVRyw0vWtVnZTk5cPTVXH+VdWrM7mIbG2Sk1prd2xld+fbYEeOW8/nW62W\neSsWmAL3c0mOyuQ79jcmOaaZAvcRqur8TC5cuSbJl5Pcm+RpSZ6XySxblyU5rbX20Fg1jqWqTk1y\n6vB0/yQ/k8lv+9cO6+5orb1yi/0vzWRK0oszmZL0BZl8FerSJD+3GiaR2ZHjNnyl6aBM/t1+ddj+\nzPzL98Rf3VrbFFzdqqqzklyQZGMmbz8vdDX9utbaBZu1WfXn244et67Pt7Gn5lvKR5Lvz+TrYrcl\neSiT8HpzkseMXdtyfGTy1ZL/kckVquszmWTiG0n+dybfQ62xaxzx2JyfyXSZiz3WLdDm2Ex+Ofpm\nkm8l+adMRgq7jv3nWY7HLcnZSf42kxkt78tkStdbM5m7/SfH/rMso2PWklztfJvtuPV8vq2aET0A\nrEar4jN6AFitBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0A\ndEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DH/j++BtPGlcC5NgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy8V0yNFRuoC",
        "colab_type": "text"
      },
      "source": [
        "단순한 로지스틱 회귀, 뉴럴넷은 28x28의 2차원 데이터를 인풋으로 받지 못한다.\n",
        "\n",
        "이미지[28 by 28] 를 납작한 array [784] 로 바꿔줄 필요가 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3itgyE_RxbO",
        "colab_type": "code",
        "outputId": "b37224d4-23be-4547-e2e7-f73a9439244a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_x = train_x.reshape([train_x.shape[0],-1])\n",
        "test_x = test_x.reshape([test_x.shape[0],-1])\n",
        "\n",
        "print(train_x.shape, test_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784) (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9KQC1-4R0Bq",
        "colab_type": "text"
      },
      "source": [
        "이미지의 값이기 때문에 0 ~ 255 사이의 값을 갖는다.\n",
        "\n",
        "전부 0~1사이의 값을 갖도록 scale을 조정하자!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWL_no_LR3U8",
        "colab_type": "code",
        "outputId": "ce39745a-de43-475b-a03d-49931f635618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('max :', train_x.max(),'  min :', train_x.min())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max : 255   min : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3An_EZn0R4wM",
        "colab_type": "code",
        "outputId": "3aa8e42f-dfea-4902-e433-0212c0636ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_num = train_x.max()\n",
        "\n",
        "train_x = train_x/max_num\n",
        "test_x = test_x/max_num\n",
        "\n",
        "print('max :', train_x.max(),'  min :', train_x.min())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max : 1.0   min : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNs8-ZziR50H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot Encoding\n",
        "\n",
        "train_y = np.eye(10)[train_y]\n",
        "test_y = np.eye(10)[test_y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0wVmwf-SGDE",
        "colab_type": "code",
        "outputId": "6a79b6d9-37aa-4984-b554-1e96ab8b6f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ_FTTj7XAtC",
        "colab_type": "text"
      },
      "source": [
        "### Sequential을 이용하여 모델링을 할거야! (추천)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJRWUyZiR8_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# model에 순차적으로 레이어를 쌓아가겠다는 의도!\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# 인풋을 받아, weight을 곱하고, bias를 더해주고\n",
        "# softmax까지 씌우는걸 한번에 하자!\n",
        "sm = keras.layers.Dense(10, input_shape=(784,),\n",
        "                       activation='softmax')\n",
        "\n",
        "# model에 위에꺼 lc를 집어 넣을거야. (최초의 레이어)\n",
        "model.add(sm)\n",
        "\n",
        "# 컴파일 해주렴\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd',\n",
        "              metrics =['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1TGiTOjXAAK",
        "colab_type": "text"
      },
      "source": [
        "### 나는 그냥 함수형으로 사용할래!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkozBGnLXLaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
        "keras.backend.clear_session()\n",
        "\n",
        "\n",
        "# 인풋을 받자!\n",
        "x = keras.layers.Input(shape = (784,))\n",
        "\n",
        "# weight을 곱하고, bias를 더하고 softmax를 씌우자!\n",
        "y = keras.layers.Dense(10, activation = 'softmax')(x) \n",
        "\n",
        "# 이러한 형태의 모델을 쓸거야! 라고 선언\n",
        "model = keras.models.Model(x, y)\n",
        "\n",
        "\n",
        "# 컴파일 해주렴\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd',\n",
        "             metrics =['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55TMUhUmTJxe",
        "colab_type": "code",
        "outputId": "3dcb038f-795c-4e8a-8040-8f0acc0bc59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 데이터를 넣어서 학습시키자!\n",
        "model.fit(train_x, train_y, epochs=100,\n",
        "          verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0710 06:24:44.897197 140133420881792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.7775 - acc: 0.8164\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.4571 - acc: 0.8808\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.4042 - acc: 0.8912\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.3777 - acc: 0.8968\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.3609 - acc: 0.9008\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.3489 - acc: 0.9039\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.3400 - acc: 0.9053\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.3327 - acc: 0.9070\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.3267 - acc: 0.9088\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.3219 - acc: 0.9099\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.3176 - acc: 0.9108\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.3139 - acc: 0.9123\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.3108 - acc: 0.9129\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.3078 - acc: 0.9140\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.3052 - acc: 0.9145\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.3028 - acc: 0.9153\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.3008 - acc: 0.9162\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2988 - acc: 0.9163\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.2970 - acc: 0.9170\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2954 - acc: 0.9171\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2939 - acc: 0.9176\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2923 - acc: 0.9180\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2910 - acc: 0.9187\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2897 - acc: 0.9191\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2885 - acc: 0.9191\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2874 - acc: 0.9197\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2863 - acc: 0.9194\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2854 - acc: 0.9203\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2844 - acc: 0.9207\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2835 - acc: 0.9206\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2825 - acc: 0.9211\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2817 - acc: 0.9213\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2809 - acc: 0.9211\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2802 - acc: 0.9214\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2796 - acc: 0.9219\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2788 - acc: 0.9220\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2781 - acc: 0.9224\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2775 - acc: 0.9227\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2768 - acc: 0.9230\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2762 - acc: 0.9229\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2756 - acc: 0.9234\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2750 - acc: 0.9234\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2745 - acc: 0.9233\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2740 - acc: 0.9235\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2735 - acc: 0.9241\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2730 - acc: 0.9240\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.2725 - acc: 0.9241\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2721 - acc: 0.9241\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2716 - acc: 0.9247\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2711 - acc: 0.9247\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2707 - acc: 0.9250\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2703 - acc: 0.9249\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.2699 - acc: 0.9252\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2695 - acc: 0.9252\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2691 - acc: 0.9253\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2688 - acc: 0.9256\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2683 - acc: 0.9257\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2680 - acc: 0.9257\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2677 - acc: 0.9261\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.2673 - acc: 0.9261\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2670 - acc: 0.9261\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2667 - acc: 0.9262\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2664 - acc: 0.9264\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2660 - acc: 0.9265\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2658 - acc: 0.9263\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2655 - acc: 0.9265\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2651 - acc: 0.9266\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2649 - acc: 0.9269\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2645 - acc: 0.9269\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2643 - acc: 0.9268\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2640 - acc: 0.9272\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.2637 - acc: 0.9270\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2634 - acc: 0.9270\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2632 - acc: 0.9270\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2630 - acc: 0.9268\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2627 - acc: 0.9271\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2625 - acc: 0.9275\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2622 - acc: 0.9274\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.2620 - acc: 0.9277\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2618 - acc: 0.9276\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2615 - acc: 0.9277\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2613 - acc: 0.9280\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2611 - acc: 0.9278\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2608 - acc: 0.9277\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2606 - acc: 0.9279\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2604 - acc: 0.9280\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2602 - acc: 0.9278\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2599 - acc: 0.9285\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2599 - acc: 0.9281\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2596 - acc: 0.9280\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2594 - acc: 0.9284\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2591 - acc: 0.9282\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2591 - acc: 0.9285\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2589 - acc: 0.9286\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.2586 - acc: 0.9286\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.2585 - acc: 0.9286\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2583 - acc: 0.9287\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.2581 - acc: 0.9289\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2579 - acc: 0.9290\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2577 - acc: 0.9294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72c59945c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc3Ap5q_bNgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_train = model.predict(train_x)\n",
        "pred_test = model.predict(test_x)\n",
        "\n",
        "single_pred_train = pred_train.argmax(axis=1)\n",
        "single_pred_test = pred_test.argmax(axis=1)\n",
        "\n",
        "\n",
        "logi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\n",
        "logi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n",
        "\n",
        "\n",
        "print('로지스틱 리그레션')\n",
        "print('트레이닝 정확도 : {:.2f}%'.format(logi_train_accuracy*100))\n",
        "print('테스트 정확도 : {:.2f}%'.format(logi_test_accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D5LN9iNR3aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "성능 확인을 위해\n",
        "Ctrl+Enter를 이용하여\n",
        "반복 실행 해보자!\n",
        "'''\n",
        "\n",
        "id = rd.randrange(0,10000)\n",
        "\n",
        "print('id = {}'.format(id))\n",
        "print('다음 그림은 숫자 {} 입니다.'.format(test_y.argmax(axis=1)[id]))\n",
        "print('모델의 예측 : {}'.format(single_pred_test[id]))\n",
        "print('모델의 카테고리별 확률 : {}'.format(np.floor(pred_test[id]*100)))\n",
        "if test_y.argmax(axis=1)[id] == single_pred_test[id] :\n",
        "    print('정답입니다')\n",
        "else : \n",
        "    print('틀렸어요')\n",
        "plt.imshow(test_x[id].reshape([28,-1]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDm-YCj7VzIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "틀린 것만 관찰해보자!\n",
        "\n",
        "Ctrl+Enter를 이용하여\n",
        "반복 실행 해보자!\n",
        "'''\n",
        "\n",
        "true_false = (test_y.argmax(axis=1) == single_pred_test)\n",
        "f_id = np.where(true_false == False)[0]\n",
        "f_n = len(f_id)\n",
        "\n",
        "id = f_id[rd.randrange(0,f_n)]\n",
        "\n",
        "\n",
        "print('id = {}'.format(id))\n",
        "print('다음 그림은 숫자 {} 입니다.'.format(test_y.argmax(axis=1)[id]))\n",
        "print('모델의 예측 : {}'.format(single_pred_test[id]))\n",
        "print('모델의 카테고리별 확률 : {}'.format(np.floor(pred_test[id]*100)))\n",
        "if test_y.argmax(axis=1)[id] == single_pred_test[id] :\n",
        "    print('정답입니다')\n",
        "else : \n",
        "    print('틀렸어요')\n",
        "plt.imshow(test_x[id].reshape([28,-1]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6gWTgHvR3du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}